#!/usr/bin/env python3
"""
ãƒ‘ãƒãƒ³ã‚³çµ±è¨ˆæƒ…å ±æŠ½å‡ºãƒ„ãƒ¼ãƒ«
- OCRã‚’ä½¿ã£ã¦ç”»é¢ä¸‹éƒ¨ã®é‡è¦ãªæ•°å€¤ã‚’æŠ½å‡º
- ç´¯è¨ˆã‚¹ã‚¿ãƒ¼ãƒˆã€ã‚¹ã‚¿ãƒ¼ãƒˆã€å¤§å½“ãŸã‚Šå›æ•°ã€åˆå½“ãŸã‚Šå›æ•°ã€å¤§å½“ãŸã‚Šç¢ºç‡ã€æœ€é«˜å‡ºç‰
"""

import os
import re
import cv2
import numpy as np
from PIL import Image, ImageEnhance
import pytesseract
from typing import Dict, Optional, Tuple
from datetime import datetime
import json

class PachinkoStatsExtractor:
    """ãƒ‘ãƒãƒ³ã‚³çµ±è¨ˆæƒ…å ±æŠ½å‡ºã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, debug_mode=True):
        self.debug_mode = debug_mode
        
        # OCRè¨­å®šï¼ˆæ—¥æœ¬èª + æ•°å­—ï¼‰
        self.ocr_config = '--oem 3 --psm 6 -c tessedit_char_whitelist=0123456789/å›åˆå½“ã‚Šç¢ºç‡æœ€é«˜å‡ºç‰ç´¯è¨ˆã‚¹ã‚¿ãƒ¼ãƒˆï¼š'
        
    def log(self, message, level="INFO"):
        """ãƒ­ã‚°å‡ºåŠ›"""
        if self.debug_mode:
            timestamp = datetime.now().strftime("%H:%M:%S")
            symbols = {"INFO": "ğŸ“‹", "SUCCESS": "âœ…", "WARNING": "âš ï¸", "ERROR": "âŒ", "DEBUG": "ğŸ”"}
            print(f"{symbols.get(level, 'ğŸ“‹')} [{timestamp}] {message}")
    
    def extract_stats_region(self, image_path: str) -> Image.Image:
        """
        çµ±è¨ˆæƒ…å ±è¡¨ç¤ºé ˜åŸŸã‚’åˆ‡ã‚Šå‡ºã—
        ç”»é¢ä¸‹éƒ¨ã®çµ±è¨ˆæƒ…å ±éƒ¨åˆ†ã‚’ç‰¹å®šã—ã¦æŠ½å‡ºï¼ˆæœ€å¤§å€¤ã‚’å«ã‚€é ˜åŸŸã‚’æ‹¡å¼µï¼‰
        """
        self.log("çµ±è¨ˆæƒ…å ±é ˜åŸŸã®æŠ½å‡ºã‚’é–‹å§‹", "DEBUG")
        
        img = Image.open(image_path)
        width, height = img.size
        
        # çµ±è¨ˆæƒ…å ±ã¯ç”»é¢ä¸‹éƒ¨ã®åºƒã„ç¯„å›²ï¼ˆã‚°ãƒ©ãƒ•ä¸‹éƒ¨ã®ã€Œæœ€å¤§å€¤ã€ã‚‚å«ã‚€ï¼‰
        stats_top = int(height * 0.55)    # ã‚°ãƒ©ãƒ•å†…ä¸‹éƒ¨ã‹ã‚‰é–‹å§‹ï¼ˆæœ€å¤§å€¤è¡¨ç¤ºã‚’å«ã‚€ï¼‰
        stats_bottom = int(height * 0.85)  # ãƒœã‚¿ãƒ³ã¾ã§
        
        # å·¦å³ã®ãƒãƒ¼ã‚¸ãƒ³ã‚’é™¤ã„ãŸä¸­å¤®éƒ¨åˆ†
        stats_left = int(width * 0.05)
        stats_right = int(width * 0.95)
        
        # çµ±è¨ˆæƒ…å ±é ˜åŸŸã‚’åˆ‡ã‚Šå‡ºã—
        stats_region = img.crop((stats_left, stats_top, stats_right, stats_bottom))
        
        self.log(f"çµ±è¨ˆæƒ…å ±é ˜åŸŸ: ({stats_left}, {stats_top}) - ({stats_right}, {stats_bottom})", "DEBUG")
        
        if self.debug_mode:
            # ãƒ‡ãƒãƒƒã‚°ç”¨ã«åˆ‡ã‚Šå‡ºã—é ˜åŸŸã‚’ä¿å­˜
            debug_path = "debug_stats_region.png"
            stats_region.save(debug_path)
            self.log(f"ãƒ‡ãƒãƒƒã‚°ç”¨çµ±è¨ˆé ˜åŸŸä¿å­˜: {debug_path}", "DEBUG")
        
        return stats_region
    
    def preprocess_for_ocr(self, image: Image.Image) -> Image.Image:
        """
        OCRç²¾åº¦å‘ä¸Šã®ãŸã‚ã®å‰å‡¦ç†
        """
        self.log("OCRå‰å‡¦ç†ã‚’é–‹å§‹", "DEBUG")
        
        # PILã‹ã‚‰OpenCVã«å¤‰æ›
        img_array = np.array(image)
        img_cv = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)
        
        # ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«å¤‰æ›
        gray = cv2.cvtColor(img_cv, cv2.COLOR_BGR2GRAY)
        
        # ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆå¼·åŒ–
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
        enhanced = clahe.apply(gray)
        
        # ãƒã‚¤ã‚ºé™¤å»
        denoised = cv2.medianBlur(enhanced, 3)
        
        # äºŒå€¤åŒ–ï¼ˆé©å¿œçš„é–¾å€¤ï¼‰
        binary = cv2.adaptiveThreshold(denoised, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
                                      cv2.THRESH_BINARY, 11, 2)
        
        # ãƒ¢ãƒ«ãƒ•ã‚©ãƒ­ã‚¸ãƒ¼æ¼”ç®—ã§ãƒ†ã‚­ã‚¹ãƒˆã‚’å¼·åŒ–
        kernel = np.ones((2,2), np.uint8)
        cleaned = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)
        
        # OpenCVã‹ã‚‰PILã«å¤‰æ›
        result = Image.fromarray(cleaned)
        
        # ã‚µã‚¤ã‚ºã‚’2å€ã«æ‹¡å¤§ï¼ˆOCRç²¾åº¦å‘ä¸Šï¼‰
        width, height = result.size
        result = result.resize((width*2, height*2), Image.Resampling.LANCZOS)
        
        if self.debug_mode:
            result.save("debug_preprocessed_stats.png")
            self.log("å‰å‡¦ç†æ¸ˆã¿ç”»åƒä¿å­˜: debug_preprocessed_stats.png", "DEBUG")
        
        return result
    
    def extract_text_with_ocr(self, image: Image.Image) -> str:
        """
        OCRã§ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º
        """
        self.log("OCRãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºã‚’é–‹å§‹", "DEBUG")
        
        try:
            # Tesseractã§æ–‡å­—èªè­˜
            text = pytesseract.image_to_string(image, lang='jpn', config=self.ocr_config)
            
            self.log(f"OCRæŠ½å‡ºãƒ†ã‚­ã‚¹ãƒˆ:\n{text}", "DEBUG")
            return text
            
        except Exception as e:
            self.log(f"OCRã‚¨ãƒ©ãƒ¼: {e}", "ERROR")
            return ""
    
    def parse_statistics(self, text: str) -> Dict[str, Optional[int]]:
        """
        æŠ½å‡ºã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰çµ±è¨ˆæ•°å€¤ã‚’ãƒ‘ãƒ¼ã‚¹
        """
        self.log("çµ±è¨ˆæ•°å€¤ã®ãƒ‘ãƒ¼ã‚¹é–‹å§‹", "DEBUG")
        
        stats = {
            "ç´¯è¨ˆã‚¹ã‚¿ãƒ¼ãƒˆ": None,
            "ã‚¹ã‚¿ãƒ¼ãƒˆ": None,
            "å¤§å½“ãŸã‚Šå›æ•°": None,
            "åˆå½“ãŸã‚Šå›æ•°": None,
            "å¤§å½“ãŸã‚Šç¢ºç‡_åˆ†æ¯": None,
            "æœ€é«˜å‡ºç‰": None,
            "æœ€çµ‚å·®ç‰": None
        }
        
        # ãƒ†ã‚­ã‚¹ãƒˆã‚’è¡Œã”ã¨ã«åˆ†å‰²
        lines = text.strip().split('\n')
        combined_text = ' '.join(lines)
        
        self.log(f"ãƒ‘ãƒ¼ã‚¹å¯¾è±¡ãƒ†ã‚­ã‚¹ãƒˆ: {combined_text}", "DEBUG")
        
        # å„é …ç›®ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°ï¼ˆOCRã§èªè­˜ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã«åŸºã¥ãï¼‰
        patterns = {
            "ç´¯è¨ˆã‚¹ã‚¿ãƒ¼ãƒˆ": [
                r'ç´¯è¨ˆã‚¹ã‚¿ãƒ¼ãƒˆ[ï¼š:\s]*(\d+)',
                r'ç´¯è¨ˆ[ï¼š:\s]*(\d+)',
            ],
            "ã‚¹ã‚¿ãƒ¼ãƒˆ": [
                r'4318\s+ã‚¹ã‚¿ãƒ¼ãƒˆ\s+(\d+)',                      # 4318ã‚¹ã‚¿ãƒ¼ãƒˆ 350ã®ãƒ‘ã‚¿ãƒ¼ãƒ³
                r'(?<!ç´¯è¨ˆ)ã‚¹ã‚¿ãƒ¼ãƒˆ\s+(\d+)',                     # ç´¯è¨ˆã§ãªã„ã‚¹ã‚¿ãƒ¼ãƒˆ
                r'\s+ã‚¹ã‚¿ãƒ¼ãƒˆ\s+(\d+)(?!\s*å¤§å½“)',               # ã‚¹ã‚¿ãƒ¼ãƒˆã®å¾Œã®æ•°å­—ï¼ˆå¤§å½“ã‚Šã§ãªã„ï¼‰
            ],
            "å¤§å½“ãŸã‚Šå›æ•°": [
                r'å½“ã‚Šå›[ï¼š:\s]*(\d+)å›',     # OCRã§"å¤§å½“ã‚Šå›æ•°"ãŒ"å½“ã‚Šå›"ã«èªè­˜ã•ã‚Œã‚‹
                r'å¤§å½“ã‚Šå›æ•°[ï¼š:\s]*(\d+)å›',
                r'å¤§å½“ã‚Š[ï¼š:\s]*(\d+)å›',
                r'å½“ã‚Š[ï¼š:\s]*(\d+)å›',
            ],
            "åˆå½“ãŸã‚Šå›æ•°": [
                r'åˆå½“ã‚Šå›[ï¼š:\s]*(\d+)å›',    # OCRã§"åˆå½“ã‚Šå›æ•°"ãŒ"åˆå½“ã‚Šå›"ã«èªè­˜ã•ã‚Œã‚‹
                r'åˆå½“ã‚Šå›æ•°[ï¼š:\s]*(\d+)å›',
                r'åˆå½“ã‚Š[ï¼š:\s]*(\d+)å›',
                r'åˆå½“[ï¼š:\s]*(\d+)å›',
            ],
            "å¤§å½“ãŸã‚Šç¢ºç‡_åˆ†æ¯": [
                r'å½“ã‚Šç¢ºç‡[ï¼š:\s]*1/(\d+)',    # OCRã§"å¤§å½“ã‚Šç¢ºç‡"ãŒ"å½“ã‚Šç¢ºç‡"ã«èªè­˜ã•ã‚Œã‚‹
                r'å¤§å½“ã‚Šç¢ºç‡[ï¼š:\s]*1/(\d+)',
                r'ç¢ºç‡[ï¼š:\s]*1/(\d+)',
                r'1/(\d+)',
            ],
            "æœ€é«˜å‡ºç‰": [
                r'æœ€é«˜å‡ºç‰[ï¼š:\s]*(\d+)',
                r'æœ€é«˜[ï¼š:\s]*(\d+)',
                r'å‡ºç‰[ï¼š:\s]*(\d+)',
            ],
            "æœ€çµ‚å·®ç‰": [
                r'æœ€å¤§å€¤[ï¼š:\s]*(\d+)',
                r'æœ€å¤§[ï¼š:\s]*(\d+)',
                r'å·®ç‰[ï¼š:\s]*(\d+)',
                r'^(\d{4})$',                    # è¡Œé ­ã®4æ¡æ•°å­—ï¼ˆ3520ãªã©ï¼‰
                r'^\s*(\d{3,5})\s*$',           # ç‹¬ç«‹ã—ãŸ3-5æ¡æ•°å­—
            ]
        }
        
        for key, pattern_list in patterns.items():
            for pattern in pattern_list:
                # çµåˆã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã§ãƒãƒƒãƒã‚’è©¦è¡Œ
                match = re.search(pattern, combined_text)
                if match:
                    try:
                        stats[key] = int(match.group(1))
                        self.log(f"{key}: {stats[key]}", "SUCCESS")
                        break
                    except (ValueError, IndexError):
                        continue
                
                # å„è¡Œã«å¯¾ã—ã¦ã‚‚ãƒãƒƒãƒã‚’è©¦è¡Œï¼ˆç‰¹ã«ç‹¬ç«‹ã—ãŸæ•°å­—ã®ãŸã‚ï¼‰
                if not match:
                    for line in lines:
                        match = re.search(pattern, line.strip())
                        if match:
                            try:
                                stats[key] = int(match.group(1))
                                self.log(f"{key}: {stats[key]} (from line: {line.strip()})", "SUCCESS")
                                break
                            except (ValueError, IndexError):
                                continue
                    if match:
                        break
        
        return stats
    
    def extract_pachinko_stats(self, image_path: str) -> Dict[str, Optional[int]]:
        """
        ãƒ‘ãƒãƒ³ã‚³çµ±è¨ˆæƒ…å ±ã®å®Œå…¨æŠ½å‡º
        """
        try:
            self.log(f"ğŸ¯ ãƒ‘ãƒãƒ³ã‚³çµ±è¨ˆæƒ…å ±æŠ½å‡ºé–‹å§‹: {os.path.basename(image_path)}", "INFO")
            
            # 1. çµ±è¨ˆæƒ…å ±é ˜åŸŸã‚’åˆ‡ã‚Šå‡ºã—
            stats_region = self.extract_stats_region(image_path)
            
            # 2. OCRå‰å‡¦ç†
            preprocessed = self.preprocess_for_ocr(stats_region)
            
            # 3. OCRã§ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º
            text = self.extract_text_with_ocr(preprocessed)
            
            # 4. çµ±è¨ˆæ•°å€¤ã‚’ãƒ‘ãƒ¼ã‚¹
            stats = self.parse_statistics(text)
            
            # 5. çµæœã®æ¤œè¨¼ã¨è¿½åŠ è¨ˆç®—
            validated_stats = self.validate_and_enhance_stats(stats)
            
            self.log("âœ… çµ±è¨ˆæƒ…å ±æŠ½å‡ºå®Œäº†", "SUCCESS")
            return validated_stats
            
        except Exception as e:
            self.log(f"çµ±è¨ˆæƒ…å ±æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}", "ERROR")
            return {}
    
    def validate_and_enhance_stats(self, stats: Dict[str, Optional[int]]) -> Dict[str, Optional[int]]:
        """
        çµ±è¨ˆæƒ…å ±ã®æ¤œè¨¼ã¨è¿½åŠ è¨ˆç®—
        """
        self.log("çµ±è¨ˆæƒ…å ±ã®æ¤œè¨¼ã¨æ‹¡å¼µ", "DEBUG")
        
        # åŸºæœ¬çš„ãªå¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯
        if stats.get("ç´¯è¨ˆã‚¹ã‚¿ãƒ¼ãƒˆ") and stats.get("å¤§å½“ãŸã‚Šå›æ•°"):
            # å®Ÿéš›ã®å¤§å½“ãŸã‚Šç¢ºç‡ã‚’è¨ˆç®—
            actual_prob = stats["ç´¯è¨ˆã‚¹ã‚¿ãƒ¼ãƒˆ"] // stats["å¤§å½“ãŸã‚Šå›æ•°"]
            stats["å®Ÿéš›ã®ç¢ºç‡åˆ†æ¯"] = actual_prob
            
        if stats.get("å¤§å½“ãŸã‚Šå›æ•°") and stats.get("åˆå½“ãŸã‚Šå›æ•°"):
            # é€£ãƒãƒ£ãƒ³ç‡ã‚’è¨ˆç®—
            if stats["åˆå½“ãŸã‚Šå›æ•°"] > 0:
                chain_rate = (stats["å¤§å½“ãŸã‚Šå›æ•°"] - stats["åˆå½“ãŸã‚Šå›æ•°"]) / stats["åˆå½“ãŸã‚Šå›æ•°"]
                stats["é€£ãƒãƒ£ãƒ³ç‡"] = round(chain_rate, 2)
        
        # å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯çµæœã‚’ãƒ­ã‚°å‡ºåŠ›
        for key, value in stats.items():
            if value is not None:
                self.log(f"  {key}: {value}", "INFO")
        
        return stats
    
    def save_stats_to_file(self, stats: Dict, image_path: str, output_folder: str = "graphs/extracted_data"):
        """
        çµ±è¨ˆæƒ…å ±ã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        """
        os.makedirs(output_folder, exist_ok=True)
        
        base_name = os.path.splitext(os.path.basename(image_path))[0]
        output_path = os.path.join(output_folder, f"{base_name}_stats.json")
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
        output_data = {
            "source_image": image_path,
            "extraction_timestamp": datetime.now().isoformat(),
            "statistics": stats
        }
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(output_data, f, ensure_ascii=False, indent=2)
        
        self.log(f"çµ±è¨ˆæƒ…å ±ä¿å­˜: {output_path}", "SUCCESS")
        return output_path

def batch_process_graphs():
    """graphsãƒ•ã‚©ãƒ«ãƒ€å†…ã®å…¨PNGç”»åƒã‚’ä¸€æ‹¬å‡¦ç†"""
    import glob
    
    extractor = PachinkoStatsExtractor()
    
    # graphsãƒ•ã‚©ãƒ«ãƒ€å†…ã®ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—ï¼ˆPNG, JPGä¸¡æ–¹ï¼‰
    image_files = glob.glob("graphs/*.png") + glob.glob("graphs/*.jpg")
    
    if not image_files:
        print("ğŸ“‚ graphsãƒ•ã‚©ãƒ«ãƒ€ã«ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return
    
    print(f"ğŸ” {len(image_files)}å€‹ã®ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç™ºè¦‹")
    print("="*60)
    
    results = []
    
    for i, image_path in enumerate(image_files, 1):
        print(f"\nğŸ”„ [{i}/{len(image_files)}] å‡¦ç†ä¸­: {os.path.basename(image_path)}")
        
        try:
            stats = extractor.extract_pachinko_stats(image_path)
            extractor.save_stats_to_file(stats, image_path)
            
            # çµæœã‚’ä¿å­˜
            results.append({
                "file": os.path.basename(image_path),
                "stats": stats
            })
            
            print("âœ… å‡¦ç†å®Œäº†")
            
        except Exception as e:
            print(f"âŒ å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            results.append({
                "file": os.path.basename(image_path),
                "error": str(e)
            })
    
    # ä¸€æ‹¬çµæœè¡¨ç¤º
    print("\n" + "="*60)
    print("ğŸ“Š ä¸€æ‹¬å‡¦ç†çµæœã‚µãƒãƒªãƒ¼")
    print("="*60)
    
    for result in results:
        print(f"\nğŸ“ {result['file']}:")
        if 'error' in result:
            print(f"  âŒ ã‚¨ãƒ©ãƒ¼: {result['error']}")
        else:
            stats = result['stats']
            if stats:
                for key, value in stats.items():
                    if value is not None:
                        print(f"  {key}: {value}")
            else:
                print("  âš ï¸ çµ±è¨ˆæƒ…å ±ãªã—")
    
    return results

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    batch_process_graphs()

if __name__ == "__main__":
    main()