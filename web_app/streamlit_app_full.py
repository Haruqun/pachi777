#!/usr/bin/env python3
"""
ãƒ‘ãƒãƒ³ã‚³ã‚°ãƒ©ãƒ•è§£æã‚·ã‚¹ãƒ†ãƒ  - ã‚·ãƒ³ãƒ—ãƒ«ç‰ˆ
ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½ã®ã¿
"""

import streamlit as st
from datetime import datetime
import cv2
import numpy as np
from PIL import Image, ImageDraw, ImageFont
import io
from web_analyzer import WebCompatibleAnalyzer
import platform
import pytesseract
import re
import json
import pandas as pd

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="ãƒ‘ãƒãƒ³ã‚³ã‚°ãƒ©ãƒ•è§£æ",
    page_icon="ğŸ°",
    layout="wide"
)

def extract_site7_data(image):
    """site7ã®ç”»åƒã‹ã‚‰OCRã§ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º"""
    try:
        # ç”»åƒã‚’ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«ã«å¤‰æ›
        if len(image.shape) == 3:
            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
        else:
            gray = image
        
        # OCRã®å‰å‡¦ç†
        # ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆã‚’ä¸Šã’ã‚‹
        alpha = 1.5  # ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆåˆ¶å¾¡
        beta = 0     # æ˜åº¦åˆ¶å¾¡
        adjusted = cv2.convertScaleAbs(gray, alpha=alpha, beta=beta)
        
        # å…¨ä½“ã®OCRå®Ÿè¡Œï¼ˆæ—¥æœ¬èªå¯¾å¿œï¼‰
        text = pytesseract.image_to_string(adjusted, lang='jpn')
        
        # æŠ½å‡ºã—ãŸã„ãƒ‡ãƒ¼ã‚¿ã®ãƒ‘ã‚¿ãƒ¼ãƒ³å®šç¾©
        data = {
            'machine_number': None,
            'total_start': None,
            'jackpot_count': None,
            'first_hit_count': None,
            'current_start': None,
            'jackpot_probability': None,
            'max_payout': None
        }
        
        # å°ç•ªå·ã®æŠ½å‡º
        lines = text.split('\n')
        for line in lines:
            if 'ç•ªå°' in line and 'ã€' in line:
                data['machine_number'] = line.strip()
        
        # æ•°å€¤ãƒ‡ãƒ¼ã‚¿ã®æŠ½å‡º
        # ç´¯è¨ˆã‚¹ã‚¿ãƒ¼ãƒˆ
        start_match = re.search(r'(\d{3,4})\s*ã‚¹ã‚¿ãƒ¼ãƒˆ', text)
        if start_match:
            data['total_start'] = start_match.group(1)
        
        # å¤§å½“ã‚Šå›æ•°
        jackpot_match = re.search(r'(\d+)\s*å›\s*å¤§å½“ã‚Š', text)
        if not jackpot_match:
            jackpot_match = re.search(r'å¤§å½“ã‚Šå›æ•°\s*(\d+)', text)
        if jackpot_match:
            data['jackpot_count'] = jackpot_match.group(1)
        
        # åˆå½“ã‚Šå›æ•°
        first_hit_match = re.search(r'åˆå½“ã‚Šå›æ•°\s*(\d+)', text)
        if not first_hit_match:
            first_hit_match = re.search(r'(\d+)\s*å›.*åˆå½“ã‚Š', text)
        if first_hit_match:
            data['first_hit_count'] = first_hit_match.group(1)
        
        # ç¾åœ¨ã®ã‚¹ã‚¿ãƒ¼ãƒˆ
        current_start_match = re.search(r'ã‚¹ã‚¿ãƒ¼ãƒˆ\s*(\d{2,3})(?!\d)', text)
        if current_start_match:
            data['current_start'] = current_start_match.group(1)
        
        # å¤§å½“ã‚Šç¢ºç‡
        prob_match = re.search(r'1/(\d{2,4})', text)
        if prob_match:
            data['jackpot_probability'] = f"1/{prob_match.group(1)}"
        
        # æœ€é«˜å‡ºç‰
        max_payout_patterns = [
            r'æœ€é«˜å‡ºç‰\s*(\d{3,5})',
            r'(\d{3,5})\s*æœ€é«˜',
            r'å‡ºç‰\s*(\d{3,5})'
            # æœ€å¾Œã®æ‰‹æ®µã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å‰Šé™¤ï¼ˆèª¤æ¤œå‡ºã‚’é˜²ããŸã‚ï¼‰
        ]
        
        for pattern in max_payout_patterns:
            max_payout_match = re.search(pattern, text)
            if max_payout_match:
                value = int(max_payout_match.group(1))
                # å¦¥å½“ãªç¯„å›²ã®å€¤ã‹ãƒã‚§ãƒƒã‚¯ï¼ˆ100-99999ï¼‰
                if 100 <= value <= 99999:
                    data['max_payout'] = str(value)
                    break
        
        
        return data
    except Exception as e:
        st.warning(f"OCRã‚¨ãƒ©ãƒ¼: {str(e)}")
        return None


# ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ€ãƒ¼ï¼ˆä¸€ç•ªæœ€åˆã«è¡¨ç¤ºï¼‰
uploaded_files = st.file_uploader(
    "ğŸ“¤ ã‚°ãƒ©ãƒ•ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
    type=['jpg', 'jpeg', 'png'],
    accept_multiple_files=True,
    help="è¤‡æ•°ã®ç”»åƒã‚’ä¸€åº¦ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã™ï¼ˆJPG, PNGå½¢å¼ï¼‰"
)

if uploaded_files:
    st.success(f"âœ… {len(uploaded_files)}æšã®ç”»åƒãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã—ãŸ")
    
    # è§£æçµæœã‚»ã‚¯ã‚·ãƒ§ãƒ³
    st.markdown("### ğŸ¯ è§£æçµæœ")
    
    # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼
    progress_bar = st.progress(0)
    status_text = st.empty()
    detail_text = st.empty()
    
    # è§£æçµæœã‚’æ ¼ç´
    analysis_results = []
    
    # å„ç”»åƒã‚’å‡¦ç†
    for idx, uploaded_file in enumerate(uploaded_files):
        # é€²æ—æ›´æ–°
        progress = (idx + 1) / len(uploaded_files)
        progress_bar.progress(progress)
        status_text.text(f'å‡¦ç†ä¸­... ({idx + 1}/{len(uploaded_files)})')
        detail_text.text(f'ğŸ“· {uploaded_file.name} ã®ç”»åƒã‚’èª­ã¿è¾¼ã¿ä¸­...')
        
        # ç”»åƒã‚’èª­ã¿è¾¼ã¿
        image = Image.open(uploaded_file)
        img_array = np.array(image)
        height, width = img_array.shape[:2]
        
        # OCRã§ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºã‚’è©¦ã¿ã‚‹
        detail_text.text(f'ğŸ” {uploaded_file.name} ã®OCRè§£æã‚’å®Ÿè¡Œä¸­...')
        ocr_data = extract_site7_data(img_array)
        
        # Pattern3: Zero Line Based ã®è‡ªå‹•æ¤œå‡º
        detail_text.text(f'ğŸ“ {uploaded_file.name} ã®ã‚°ãƒ©ãƒ•é ˜åŸŸã‚’æ¤œå‡ºä¸­...')
        hsv = cv2.cvtColor(img_array, cv2.COLOR_RGB2HSV)
        orange_mask = cv2.inRange(hsv, np.array([10, 100, 100]), np.array([30, 255, 255]))
        orange_bottom = 0
        
        # ã‚ªãƒ¬ãƒ³ã‚¸ãƒãƒ¼ã®æ¤œå‡º
        for y in range(height//2):
            if np.sum(orange_mask[y, :]) > width * 0.3 * 255:
                orange_bottom = y
        
        # ã‚ªãƒ¬ãƒ³ã‚¸ãƒãƒ¼ã®ä¸‹ç«¯ã‚’æ­£ç¢ºã«è¦‹ã¤ã‘ã‚‹
        if orange_bottom > 0:
            for y in range(orange_bottom, min(orange_bottom + 100, height)):
                if np.sum(orange_mask[y, :]) < width * 0.1 * 255:
                    orange_bottom = y
                    break
        else:
            orange_bottom = 150
        
        # ã‚¼ãƒ­ãƒ©ã‚¤ãƒ³æ¤œå‡º
        gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)
        search_start = orange_bottom + 50
        search_end = min(height - 100, orange_bottom + 400)
        
        best_score = 0
        zero_line_y = (search_start + search_end) // 2
        
        for y in range(search_start, search_end):
            row = gray[y, 100:width-100]
            darkness = 1.0 - (np.mean(row) / 255.0)
            uniformity = 1.0 - (np.std(row) / 128.0)
            score = darkness * 0.5 + uniformity * 0.5
            
            if score > best_score:
                best_score = score
                zero_line_y = y
        
        # åˆ‡ã‚ŠæŠœãç¯„å›²ã‚’è¨­å®šï¼ˆæœ€çµ‚èª¿æ•´å€¤ï¼‰
        top = max(0, zero_line_y - 246)  # 0ãƒ©ã‚¤ãƒ³ã‹ã‚‰ä¸Š246px
        bottom = min(height, zero_line_y + 247)  # 0ãƒ©ã‚¤ãƒ³ã‹ã‚‰ä¸‹247px
        left = 125  # å·¦å³ã®ä½™ç™½125px
        right = width - 125  # å·¦å³ã®ä½™ç™½125px
        
        # åˆ‡ã‚ŠæŠœãå®Ÿè¡Œ
        cropped_img = img_array[int(top):int(bottom), int(left):int(right)].copy()
        
        # ã‚°ãƒªãƒƒãƒ‰ãƒ©ã‚¤ãƒ³ã‚’è¿½åŠ 
        # åˆ‡ã‚ŠæŠœãç”»åƒã®é«˜ã•ã¯493pxï¼ˆ246+247ï¼‰
        # æœ€ä¸Šéƒ¨ãŒ+30000ã€æœ€ä¸‹éƒ¨ãŒ-30000ãªã®ã§ã€60000ã®ç¯„å›²ã‚’493pxã§è¡¨ç¾
        # 1pxã‚ãŸã‚Šç´„121.7ç‰
        crop_height = cropped_img.shape[0]
        zero_line_in_crop = zero_line_y - top  # åˆ‡ã‚ŠæŠœãç”»åƒå†…ã§ã®0ãƒ©ã‚¤ãƒ³ä½ç½®
        
        # ã‚¹ã‚±ãƒ¼ãƒ«è¨ˆç®—ï¼ˆä¸Šä¸‹246,247pxã§Â±30000ï¼‰
        scale = 30000 / 246  # ç´„121.95ç‰/px
        
        # ã‚°ãƒªãƒƒãƒ‰ãƒ©ã‚¤ãƒ³æç”»ï¼ˆå›ºå®šå€¤ï¼‰
        # +30000ãƒ©ã‚¤ãƒ³ï¼ˆæœ€ä¸Šéƒ¨ï¼‰
        y_30k = -1  # å›ºå®šèª¿æ•´å€¤
        cv2.line(cropped_img, (0, y_30k), (cropped_img.shape[1], y_30k), (128, 128, 128), 2)
        cv2.putText(cropped_img, '+30000', (10, max(20, y_30k + 20)), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (64, 64, 64), 1)
        
        # +20000ãƒ©ã‚¤ãƒ³
        y_20k = int(zero_line_in_crop - (20000 / scale)) - 2  # å›ºå®šèª¿æ•´å€¤
        if 0 < y_20k < crop_height:
            cv2.line(cropped_img, (0, y_20k), (cropped_img.shape[1], y_20k), (128, 128, 128), 1)
            cv2.putText(cropped_img, '+20000', (10, y_20k - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (64, 64, 64), 1)
        
        # +10000ãƒ©ã‚¤ãƒ³
        y_10k = int(zero_line_in_crop - (10000 / scale)) - 1  # å›ºå®šèª¿æ•´å€¤
        if 0 < y_10k < crop_height:
            cv2.line(cropped_img, (0, y_10k), (cropped_img.shape[1], y_10k), (128, 128, 128), 1)
            cv2.putText(cropped_img, '+10000', (10, y_10k - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (64, 64, 64), 1)
        
        # 0ãƒ©ã‚¤ãƒ³
        y_0 = int(zero_line_in_crop)  # èª¿æ•´ãªã—
        if 0 < y_0 < crop_height:
            cv2.line(cropped_img, (0, y_0), (cropped_img.shape[1], y_0), (255, 0, 0), 2)
            cv2.putText(cropped_img, '0', (10, y_0 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 1)
        
        # -10000ãƒ©ã‚¤ãƒ³
        y_minus_10k = int(zero_line_in_crop + (10000 / scale)) + 1  # å›ºå®šèª¿æ•´å€¤
        if 0 < y_minus_10k < crop_height:
            cv2.line(cropped_img, (0, y_minus_10k), (cropped_img.shape[1], y_minus_10k), (128, 128, 128), 1)
            cv2.putText(cropped_img, '-10000', (10, y_minus_10k - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (64, 64, 64), 1)
        
        # -20000ãƒ©ã‚¤ãƒ³
        y_minus_20k = int(zero_line_in_crop + (20000 / scale)) + 1  # å›ºå®šèª¿æ•´å€¤
        if 0 < y_minus_20k < crop_height:
            cv2.line(cropped_img, (0, y_minus_20k), (cropped_img.shape[1], y_minus_20k), (128, 128, 128), 1)
            cv2.putText(cropped_img, '-20000', (10, y_minus_20k - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (64, 64, 64), 1)
        
        # -30000ãƒ©ã‚¤ãƒ³ï¼ˆæœ€ä¸‹éƒ¨ï¼‰
        y_minus_30k = crop_height - 1 + 2  # å›ºå®šèª¿æ•´å€¤
        y_minus_30k = min(max(0, y_minus_30k), crop_height - 1)  # ç”»åƒç¯„å›²å†…ã«åˆ¶é™
        cv2.line(cropped_img, (0, y_minus_30k), (cropped_img.shape[1], y_minus_30k), (128, 128, 128), 2)
        cv2.putText(cropped_img, '-30000', (10, max(10, y_minus_30k - 10)), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (64, 64, 64), 1)
        
        # è§£æã‚’è‡ªå‹•å®Ÿè¡Œ
        detail_text.text(f'ğŸ“Š {uploaded_file.name} ã®ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ã‚’è§£æä¸­...')
        with st.spinner(f"ã‚°ãƒ©ãƒ•ã‚’è§£æä¸­... ({idx + 1}/{len(uploaded_files)})"):
            # ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼ã‚’åˆæœŸåŒ–
            analyzer = WebCompatibleAnalyzer()
            
            # ã‚°ãƒªãƒƒãƒ‰ãƒ©ã‚¤ãƒ³ãªã—ã®ç”»åƒã‚’ä½¿ç”¨
            analysis_img = img_array[int(top):int(bottom), int(left):int(right)].copy()
            
            # 0ãƒ©ã‚¤ãƒ³ã®ä½ç½®ã‚’è¨­å®š
            analyzer.zero_y = zero_line_in_crop
            analyzer.scale = 30000 / 246  # ã‚¹ã‚±ãƒ¼ãƒ«è¨­å®š
            
            # ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
            graph_data_points, dominant_color, _ = analyzer.extract_graph_data(analysis_img)
            
            if graph_data_points:
                # ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰å€¤ã®ã¿ã‚’æŠ½å‡º
                graph_values = [value for x, value in graph_data_points]
                
                # çµ±è¨ˆæƒ…å ±ã‚’è¨ˆç®—
                max_val = max(graph_values)
                min_val = min(graph_values)
                current_val = graph_values[-1] if graph_values else 0
                
                # MAXãŒãƒã‚¤ãƒŠã‚¹ã®å ´åˆã¯0ã‚’è¡¨ç¤º
                if max_val < 0:
                    max_val = 0
                
                # åˆå½“ãŸã‚Šå€¤ã‚’æ¢ã™ï¼ˆproductionç‰ˆã¨åŒã˜ãƒ­ã‚¸ãƒƒã‚¯ï¼‰
                first_hit_val = 0
                first_hit_x = None
                min_payout = 100  # æœ€ä½æ‰•ã„å‡ºã—ç‰æ•°
                
                # æ–¹æ³•1: 100ç‰ä»¥ä¸Šã®æ€¥æ¿€ãªå¢—åŠ ã‚’æ¤œå‡º
                for i in range(1, min(len(graph_values)-2, 150)):  # æœ€å¤§150ç‚¹ã¾ã§æ¢ç´¢
                    current_increase = graph_values[i+1] - graph_values[i]
                    
                    # 100ç‰ä»¥ä¸Šã®å¢—åŠ ã‚’æ¤œå‡º
                    if current_increase > min_payout:
                        # æ¬¡ã®ç‚¹ã‚‚ä¸Šæ˜‡ã¾ãŸã¯ç¶­æŒã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªï¼ˆãƒã‚¤ã‚ºé™¤å¤–ï¼‰
                        if graph_values[i+2] >= graph_values[i+1] - 50:
                            # åˆå½“ãŸã‚Šã¯å¿…ãšãƒã‚¤ãƒŠã‚¹å€¤ã‹ã‚‰
                            if graph_values[i] < 0:
                                first_hit_val = graph_values[i]
                                first_hit_x = i
                                break
                
                # æ–¹æ³•2: æ¸›å°‘å‚¾å‘ã‹ã‚‰ã®æ€¥ä¸Šæ˜‡ã‚’æ¤œå‡º
                if first_hit_x is None:
                    window_size = 5
                    for i in range(window_size, len(graph_values)-1):
                        # éå»ã®å‚¾å‘ã‚’è¨ˆç®—
                        past_window = graph_values[max(0, i-window_size):i]
                        if len(past_window) >= 2:
                            avg_slope = (past_window[-1] - past_window[0]) / len(past_window)
                            
                            # ç¾åœ¨ã®å¤‰åŒ–
                            current_change = graph_values[i+1] - graph_values[i]
                            
                            # æ¸›å°‘å‚¾å‘ã‹ã‚‰ã®æ€¥ä¸Šæ˜‡
                            if avg_slope <= 0 and current_change > min_payout:
                                if i + 2 < len(graph_values) and graph_values[i+2] > graph_values[i+1] - 50:
                                    # åˆå½“ãŸã‚Šã¯å¿…ãšãƒã‚¤ãƒŠã‚¹å€¤
                                    if graph_values[i] < 0:
                                        first_hit_val = graph_values[i]
                                        first_hit_x = i
                                        break
                
                # åˆå½“ãŸã‚Šå€¤ãŒãƒ—ãƒ©ã‚¹ã®å ´åˆã¯0ã‚’è¡¨ç¤º
                if first_hit_val > 0:
                    first_hit_val = 0
                
                # ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ç”»åƒã‚’ä½œæˆ
                overlay_img = cropped_img.copy()
                    
                # æ¤œå‡ºã•ã‚ŒãŸã‚°ãƒ©ãƒ•ãƒ©ã‚¤ãƒ³ã‚’æç”»
                prev_x = None
                prev_y = None
                
                # ç·‘è‰²ã§çµ±ä¸€ï¼ˆè¦‹ã‚„ã™ã•é‡è¦–ï¼‰
                draw_color = (0, 255, 0)  # ç·‘è‰²å›ºå®š
                
                # ã‚°ãƒ©ãƒ•ãƒã‚¤ãƒ³ãƒˆã‚’æç”»
                for x, value in graph_data_points:
                    # Yåº§æ¨™ã‚’è¨ˆç®—ï¼ˆ0ãƒ©ã‚¤ãƒ³ã‹ã‚‰ã®ç›¸å¯¾ä½ç½®ï¼‰
                    y = int(zero_line_in_crop - (value / analyzer.scale))
                    
                    # ç”»åƒç¯„å›²å†…ã‹ãƒã‚§ãƒƒã‚¯
                    if 0 <= y < overlay_img.shape[0] and 0 <= x < overlay_img.shape[1]:
                        # ç‚¹ã‚’æç”»ï¼ˆã‚ˆã‚Šè¦‹ã‚„ã™ãã™ã‚‹ãŸã‚ï¼‰
                        cv2.circle(overlay_img, (int(x), y), 2, draw_color, -1)
                        
                        # ç·šã§æ¥ç¶š
                        if prev_x is not None and prev_y is not None:
                            cv2.line(overlay_img, (int(prev_x), int(prev_y)), (int(x), y), draw_color, 2)
                        
                        prev_x = x
                        prev_y = y
                
                # æœ€é«˜å€¤ã€æœ€ä½å€¤ã€åˆå½“ãŸã‚Šã®ä½ç½®ã‚’è¦‹ã¤ã‘ã‚‹
                # MAXãŒ0ã«ä¿®æ­£ã•ã‚ŒãŸå ´åˆã¯ã€å…ƒã®æœ€é«˜å€¤ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä¿æŒ
                if max_val == 0 and max(graph_values) < 0:
                    max_idx = graph_values.index(max(graph_values))
                else:
                    max_idx = graph_values.index(max_val)
                min_idx = graph_values.index(min_val)
                
                # æ¨ªç·šã‚’æç”»ï¼ˆæœ€ä½å€¤ã€æœ€é«˜å€¤ã€ç¾åœ¨å€¤ã€åˆå½“ãŸã‚Šå€¤ï¼‰
                # æœ€é«˜å€¤ãƒ©ã‚¤ãƒ³ï¼ˆç«¯ã‹ã‚‰ç«¯ã¾ã§ï¼‰
                max_y = int(zero_line_in_crop - (max_val / analyzer.scale))
                if 0 <= max_y < overlay_img.shape[0]:
                    # ç«¯ã‹ã‚‰ç«¯ã¾ã§ç·šã‚’å¼•ã
                    cv2.line(overlay_img, (0, max_y), (overlay_img.shape[1], max_y), (0, 255, 255), 2)
                    # æœ€é«˜å€¤ã®ç‚¹ã«å¤§ãã‚ã®å††ã‚’æç”»
                    max_x = graph_data_points[max_idx][0]
                    cv2.circle(overlay_img, (int(max_x), max_y), 8, (0, 255, 255), -1)
                    cv2.circle(overlay_img, (int(max_x), max_y), 10, (0, 200, 200), 2)
                    # èƒŒæ™¯ä»˜ããƒ†ã‚­ã‚¹ãƒˆï¼ˆç™½èƒŒæ™¯ã€æ¿ƒã„é»„è‰²æ–‡å­—ï¼‰å³ç«¯ã«è¡¨ç¤º
                    text = f'MAX: {int(max_val):,}'
                    text_width = 140
                    text_y = max_y if max_y > 20 else max_y + 20  # ä¸Šç«¯ã§è¦‹åˆ‡ã‚Œãªã„ã‚ˆã†ã«èª¿æ•´
                    cv2.rectangle(overlay_img, (overlay_img.shape[1] - text_width - 15, text_y - 15), 
                                 (overlay_img.shape[1] - 10, text_y + 5), (255, 255, 255), -1)
                    cv2.putText(overlay_img, text, (overlay_img.shape[1] - text_width - 10, text_y), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 150, 150), 1, cv2.LINE_AA)
                
                # æœ€ä½å€¤ãƒ©ã‚¤ãƒ³ï¼ˆç«¯ã‹ã‚‰ç«¯ã¾ã§ï¼‰
                min_y = int(zero_line_in_crop - (min_val / analyzer.scale))
                if 0 <= min_y < overlay_img.shape[0]:
                    # ç«¯ã‹ã‚‰ç«¯ã¾ã§ç·šã‚’å¼•ã
                    cv2.line(overlay_img, (0, min_y), (overlay_img.shape[1], min_y), (255, 0, 255), 2)
                    # æœ€ä½å€¤ã®ç‚¹ã«å¤§ãã‚ã®å††ã‚’æç”»
                    min_x = graph_data_points[min_idx][0]
                    cv2.circle(overlay_img, (int(min_x), min_y), 8, (255, 0, 255), -1)
                    cv2.circle(overlay_img, (int(min_x), min_y), 10, (200, 0, 200), 2)
                    # èƒŒæ™¯ä»˜ããƒ†ã‚­ã‚¹ãƒˆï¼ˆç™½èƒŒæ™¯ã€æ¿ƒã„ãƒã‚¼ãƒ³ã‚¿æ–‡å­—ï¼‰å³ç«¯ã«è¡¨ç¤º
                    text = f'MIN: {int(min_val):,}'
                    text_width = 140
                    text_y = min_y if (min_y > 20 and min_y < overlay_img.shape[0] - 20) else (20 if min_y <= 20 else overlay_img.shape[0] - 20)
                    cv2.rectangle(overlay_img, (overlay_img.shape[1] - text_width - 15, text_y - 15), 
                                 (overlay_img.shape[1] - 10, text_y + 5), (255, 255, 255), -1)
                    cv2.putText(overlay_img, text, (overlay_img.shape[1] - text_width - 10, text_y), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (150, 0, 150), 1, cv2.LINE_AA)
                
                # ç¾åœ¨å€¤ãƒ©ã‚¤ãƒ³ï¼ˆç«¯ã‹ã‚‰ç«¯ã¾ã§ï¼‰
                current_y = int(zero_line_in_crop - (current_val / analyzer.scale))
                if 0 <= current_y < overlay_img.shape[0]:
                    cv2.line(overlay_img, (0, current_y), (overlay_img.shape[1], current_y), (255, 255, 0), 2)
                    # èƒŒæ™¯ä»˜ããƒ†ã‚­ã‚¹ãƒˆï¼ˆç™½èƒŒæ™¯ã€æ¿ƒã„ã‚·ã‚¢ãƒ³æ–‡å­—ï¼‰å³ç«¯ã«è¡¨ç¤º
                    text = f'CURRENT: {int(current_val):,}'
                    text_width = 160
                    text_y = current_y - 10 if current_y > 30 else current_y + 15
                    cv2.rectangle(overlay_img, (overlay_img.shape[1] - text_width - 15, text_y - 15), 
                                 (overlay_img.shape[1] - 10, text_y + 5), (255, 255, 255), -1)
                    cv2.putText(overlay_img, text, (overlay_img.shape[1] - text_width - 10, text_y), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (150, 150, 0), 1, cv2.LINE_AA)
                
                # åˆå½“ãŸã‚Šå€¤ãƒ©ã‚¤ãƒ³ï¼ˆç«¯ã‹ã‚‰ç«¯ã¾ã§ï¼‰
                if first_hit_x is not None and first_hit_val != 0:  # åˆå½“ãŸã‚ŠãŒã‚ã‚‹å ´åˆ
                    first_hit_y = int(zero_line_in_crop - (first_hit_val / analyzer.scale))
                    if 0 <= first_hit_y < overlay_img.shape[0]:
                        # ç«¯ã‹ã‚‰ç«¯ã¾ã§ç·šã‚’å¼•ã
                        cv2.line(overlay_img, (0, first_hit_y), (overlay_img.shape[1], first_hit_y), (155, 48, 255), 2)
                        # åˆå½“ãŸã‚Šã®ç‚¹ã«å¤§ãã‚ã®å††ã‚’æç”»
                        first_hit_graph_x = graph_data_points[first_hit_x][0]
                        cv2.circle(overlay_img, (int(first_hit_graph_x), first_hit_y), 8, (155, 48, 255), -1)
                        cv2.circle(overlay_img, (int(first_hit_graph_x), first_hit_y), 10, (120, 30, 200), 2)
                        # èƒŒæ™¯ä»˜ããƒ†ã‚­ã‚¹ãƒˆï¼ˆç™½èƒŒæ™¯ã€ç´«æ–‡å­—ï¼‰å³ç«¯ã«è¡¨ç¤º
                        text = f'FIRST HIT: {int(first_hit_val):,}'
                        text_width = 150
                        text_y = first_hit_y if (first_hit_y > 20 and first_hit_y < overlay_img.shape[0] - 20) else (20 if first_hit_y <= 20 else overlay_img.shape[0] - 20)
                        cv2.rectangle(overlay_img, (overlay_img.shape[1] - text_width - 15, text_y - 15), 
                                     (overlay_img.shape[1] - 10, text_y + 5), (255, 255, 255), -1)
                        cv2.putText(overlay_img, text, (overlay_img.shape[1] - text_width - 10, text_y), 
                                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (100, 0, 150), 1, cv2.LINE_AA)
                
                # çµæœã‚’ä¿å­˜
                analysis_results.append({
                    'name': uploaded_file.name,
                    'original_image': img_array,  # å…ƒç”»åƒã‚’ä¿å­˜
                    'cropped_image': cropped_img,  # åˆ‡ã‚ŠæŠœãç”»åƒ
                    'overlay_image': overlay_img,  # ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ç”»åƒ
                    'success': True,
                    'max_val': int(max_val),
                    'min_val': int(min_val),
                    'current_val': int(current_val),
                    'first_hit_val': int(first_hit_val) if first_hit_x is not None else None,
                    'dominant_color': dominant_color,
                    'ocr_data': ocr_data  # OCRãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
                })
            else:
                # è§£æå¤±æ•—æ™‚
                analysis_results.append({
                    'name': uploaded_file.name,
                    'original_image': img_array,  # å…ƒç”»åƒã‚’ä¿å­˜
                    'cropped_image': cropped_img,
                    'overlay_image': cropped_img,  # è§£æå¤±æ•—æ™‚ã¯åˆ‡ã‚ŠæŠœãç”»åƒã‚’ä½¿ç”¨
                    'success': False,
                    'ocr_data': ocr_data  # OCRãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
                })
    
    # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã‚’å®Œäº†
    progress_bar.progress(1.0)
    status_text.text('âœ… å…¨ã¦ã®ç”»åƒã®å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸï¼')
    detail_text.empty()
    
    # çµæœã‚’ã‚°ãƒªãƒƒãƒ‰è¡¨ç¤º
    st.markdown("### ğŸ“Š è§£æçµæœä¸€è¦§")
    
    # è§£æçµæœã‚’2åˆ—ã§è¡¨ç¤º
    cols = st.columns(2)
    
    for idx, result in enumerate(analysis_results):
        with cols[idx % 2]:
            # å°ç•ªå·ã‚’å„ªå…ˆè¡¨ç¤ºã€ãªã‘ã‚Œã°ãƒ•ã‚¡ã‚¤ãƒ«å
            if result.get('ocr_data') and result['ocr_data'].get('machine_number'):
                display_name = result['ocr_data']['machine_number']
            else:
                display_name = result['name']
            st.markdown(f"#### {idx + 1}. {display_name}")
            
            # è§£æçµæœç”»åƒ
            st.image(result['overlay_image'], use_column_width=True)
            
            # å…ƒç”»åƒã‚’æŠ˜ã‚ŠãŸãŸã¿å¯èƒ½ã«
            with st.expander("ğŸ“· å…ƒç”»åƒã‚’è¡¨ç¤º"):
                st.image(result['original_image'], use_column_width=True)
            
            # ãƒ†ã‚¹ãƒˆåˆ‡ã‚ŠæŠœãæ©Ÿèƒ½ï¼ˆé–‹ç™ºç”¨ï¼‰
            with st.expander("ğŸ§ª åˆ‡ã‚ŠæŠœããƒ†ã‚¹ãƒˆï¼ˆé–‹ç™ºç”¨ï¼‰"):
                st.caption("â€» ã“ã‚Œã¯é–‹ç™ºç”¨ã®ãƒ†ã‚¹ãƒˆæ©Ÿèƒ½ã§ã™ã€‚é€šå¸¸ã®è§£æã«ã¯å½±éŸ¿ã—ã¾ã›ã‚“ã€‚")
                
                # ç¾çŠ¶ã®ä»•æ§˜
                st.markdown("#### ç¾çŠ¶ã®ä»•æ§˜ï¼ˆãƒ¡ã‚¤ãƒ³å‡¦ç†ï¼‰")
                try:
                    # ç¾åœ¨ã®å®Ÿè£…ã¨åŒã˜ãƒ­ã‚¸ãƒƒã‚¯
                    test_hsv = cv2.cvtColor(result['original_image'], cv2.COLOR_RGB2HSV)
                    test_orange_mask = cv2.inRange(test_hsv, np.array([10, 100, 100]), np.array([30, 255, 255]))
                    test_height, test_width = result['original_image'].shape[:2]
                    test_gray = cv2.cvtColor(result['original_image'], cv2.COLOR_RGB2GRAY)
                    
                    # ã‚ªãƒ¬ãƒ³ã‚¸ãƒãƒ¼ã®æ¤œå‡º
                    current_orange_bottom = 0
                    for y in range(test_height//2):
                        if np.sum(test_orange_mask[y, :]) > test_width * 0.3 * 255:
                            current_orange_bottom = y
                    
                    # ã‚ªãƒ¬ãƒ³ã‚¸ãƒãƒ¼ã®ä¸‹ç«¯ã‚’æ­£ç¢ºã«è¦‹ã¤ã‘ã‚‹
                    if current_orange_bottom > 0:
                        for y in range(current_orange_bottom, min(current_orange_bottom + 100, test_height)):
                            if np.sum(test_orange_mask[y, :]) < test_width * 0.1 * 255:
                                current_orange_bottom = y
                                break
                    else:
                        current_orange_bottom = 150
                    
                    # ã‚¼ãƒ­ãƒ©ã‚¤ãƒ³æ¤œå‡º
                    search_start_current = current_orange_bottom + 50
                    search_end_current = min(test_height - 100, current_orange_bottom + 400)
                    
                    best_score_current = 0
                    zero_line_current = (search_start_current + search_end_current) // 2
                    
                    for y in range(search_start_current, search_end_current):
                        row = test_gray[y, 100:test_width-100]
                        darkness = 1.0 - (np.mean(row) / 255.0)
                        uniformity = 1.0 - (np.std(row) / 128.0)
                        score = darkness * 0.5 + uniformity * 0.5
                        
                        if score > best_score_current:
                            best_score_current = score
                            zero_line_current = y
                    
                    # åˆ‡ã‚ŠæŠœã
                    top_current = max(0, zero_line_current - 246)
                    bottom_current = min(test_height, zero_line_current + 247)
                    left_current = 125
                    right_current = test_width - 125
                    
                    cropped_current = result['original_image'][int(top_current):int(bottom_current), int(left_current):int(right_current)].copy()
                    
                    # ã‚°ãƒªãƒƒãƒ‰ãƒ©ã‚¤ãƒ³è¿½åŠ 
                    zero_in_crop_current = zero_line_current - top_current
                    cv2.line(cropped_current, (0, int(zero_in_crop_current)), (cropped_current.shape[1], int(zero_in_crop_current)), (0, 0, 255), 2)
                    cv2.putText(cropped_current, 'Zero (Current)', (10, int(zero_in_crop_current) - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)
                    
                    st.image(cropped_current, caption="ç¾çŠ¶ã®ä»•æ§˜ã«ã‚ˆã‚‹åˆ‡ã‚ŠæŠœã", use_column_width=True)
                    st.info(f"ã‚ªãƒ¬ãƒ³ã‚¸ãƒãƒ¼: Y={current_orange_bottom}, ã‚¼ãƒ­ãƒ©ã‚¤ãƒ³: Y={zero_line_current}, ã‚¹ã‚³ã‚¢: {best_score_current:.3f}")
                    
                except Exception as e:
                    st.error(f"ç¾çŠ¶ã®ä»•æ§˜ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {str(e)}")
                
                # Aæ¡ˆ: ã‚°ãƒ©ãƒ•ã‚¨ãƒªã‚¢ä¸­å¤®æ–¹å¼
                st.markdown("#### Aæ¡ˆ: ã‚°ãƒ©ãƒ•ã‚¨ãƒªã‚¢ä¸­å¤®æ–¹å¼")
                try:
                    # ã‚°ãƒ©ãƒ•ã‚¨ãƒªã‚¢ã®æ¤œå‡º
                    test_gray = cv2.cvtColor(result['original_image'], cv2.COLOR_RGB2GRAY)
                    test_height, test_width = result['original_image'].shape[:2]
                    
                    # ã‚ªãƒ¬ãƒ³ã‚¸ãƒãƒ¼ã®ä½ç½®ã¯æ—¢ã«æ¤œå‡ºæ¸ˆã¿ãªã®ã§ã€ãã“ã‹ã‚‰æ¢ã™
                    # â€» ã‚ªãƒ¬ãƒ³ã‚¸ãƒãƒ¼ã®ä½ç½®ã‚’å†æ¤œå‡º
                    test_hsv = cv2.cvtColor(result['original_image'], cv2.COLOR_RGB2HSV)
                    test_orange_mask = cv2.inRange(test_hsv, np.array([10, 100, 100]), np.array([30, 255, 255]))
                    test_orange_bottom = 0
                    
                    for y in range(test_height//2):
                        if np.sum(test_orange_mask[y, :]) > test_width * 0.3 * 255:
                            test_orange_bottom = y
                    
                    if test_orange_bottom > 0:
                        for y in range(test_orange_bottom, min(test_orange_bottom + 100, test_height)):
                            if np.sum(test_orange_mask[y, :]) < test_width * 0.1 * 255:
                                test_orange_bottom = y
                                break
                    
                    # ã‚°ãƒ©ãƒ•ã‚¨ãƒªã‚¢ã®ä¸Šç«¯ï¼ˆã‚ªãƒ¬ãƒ³ã‚¸ãƒãƒ¼ã®ä¸‹ï¼‰
                    graph_top_a = test_orange_bottom + 20
                    
                    # ã‚°ãƒ©ãƒ•ã‚¨ãƒªã‚¢ã®ä¸‹ç«¯ã‚’è¦‹ã¤ã‘ã‚‹ï¼ˆçµ±è¨ˆæƒ…å ±ã®ä¸Šï¼‰
                    graph_bottom_a = test_height - 300  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
                    for y in range(test_height - 300, test_orange_bottom, -1):
                        row = test_gray[y, test_width//4:test_width*3//4]
                        # èƒŒæ™¯ãŒæ€¥ã«æš—ããªã‚‹éƒ¨åˆ†ã‚’æ¢ã™ï¼ˆçµ±è¨ˆæƒ…å ±ã‚¨ãƒªã‚¢ï¼‰
                        if np.mean(row) < 150:
                            graph_bottom_a = y
                            break
                    
                    # ã‚°ãƒ©ãƒ•ã‚¨ãƒªã‚¢ã®ä¸­å¤®ã‚’ã‚¼ãƒ­ãƒ©ã‚¤ãƒ³ã¨ã™ã‚‹
                    zero_line_a = graph_top_a + (graph_bottom_a - graph_top_a) // 2
                    
                    # åˆ‡ã‚ŠæŠœã
                    top_a = max(0, zero_line_a - 246)
                    bottom_a = min(test_height, zero_line_a + 247)
                    left_a = 125
                    right_a = test_width - 125
                    
                    cropped_a = result['original_image'][int(top_a):int(bottom_a), int(left_a):int(right_a)].copy()
                    
                    # ã‚°ãƒªãƒƒãƒ‰ãƒ©ã‚¤ãƒ³è¿½åŠ ï¼ˆç°¡æ˜“ç‰ˆï¼‰
                    zero_in_crop_a = zero_line_a - top_a
                    cv2.line(cropped_a, (0, int(zero_in_crop_a)), (cropped_a.shape[1], int(zero_in_crop_a)), (255, 0, 0), 2)
                    cv2.putText(cropped_a, 'Zero (A)', (10, int(zero_in_crop_a) - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)
                    
                    st.image(cropped_a, caption="Aæ¡ˆã«ã‚ˆã‚‹åˆ‡ã‚ŠæŠœã", use_column_width=True)
                    st.info(f"ã‚°ãƒ©ãƒ•ã‚¨ãƒªã‚¢: top={graph_top_a}, bottom={graph_bottom_a}, zero={zero_line_a}")
                    
                except Exception as e:
                    st.error(f"Aæ¡ˆã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {str(e)}")
                
                # Bæ¡ˆ: æš—ã„æ°´å¹³ç·šæ¤œå‡ºæ–¹å¼
                st.markdown("#### Bæ¡ˆ: æš—ã„æ°´å¹³ç·šæ¤œå‡ºæ–¹å¼")
                try:
                    # ã‚ˆã‚Šåºƒã„ç¯„å›²ã§æš—ã„ç·šã‚’æ¢ã™
                    search_start_b = test_orange_bottom + 50
                    search_end_b = test_height - 200
                    
                    best_score_b = 0
                    zero_line_b = (search_start_b + search_end_b) // 2
                    scores_b = []
                    
                    # ã‚¨ãƒƒã‚¸æ¤œå‡ºã‚’ä½¿ç”¨
                    edges = cv2.Canny(test_gray, 50, 150)
                    
                    for y in range(search_start_b, search_end_b):
                        # å·¦å³ã®ä½™ç™½ã‚’è€ƒæ…®
                        left_margin = test_width // 6
                        right_margin = test_width - left_margin
                        
                        # ã‚¨ãƒƒã‚¸ã®å¼·åº¦ã‚’ãƒã‚§ãƒƒã‚¯
                        edge_row = edges[y, left_margin:right_margin]
                        edge_strength = np.sum(edge_row > 0) / len(edge_row)
                        
                        # ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«å€¤ã‚’ãƒã‚§ãƒƒã‚¯
                        gray_row = test_gray[y, left_margin:right_margin]
                        
                        # ã‚¹ã‚³ã‚¢è¨ˆç®—
                        darkness = 1.0 - (np.mean(gray_row) / 255.0)
                        uniformity = 1.0 - (np.std(gray_row) / 128.0)
                        score = darkness * 0.4 + uniformity * 0.3 + edge_strength * 0.3
                        
                        scores_b.append((y, score))
                        
                        if score > best_score_b:
                            best_score_b = score
                            zero_line_b = y
                    
                    # åˆ‡ã‚ŠæŠœã
                    top_b = max(0, zero_line_b - 246)
                    bottom_b = min(test_height, zero_line_b + 247)
                    left_b = 125
                    right_b = test_width - 125
                    
                    cropped_b = result['original_image'][int(top_b):int(bottom_b), int(left_b):int(right_b)].copy()
                    
                    # ã‚°ãƒªãƒƒãƒ‰ãƒ©ã‚¤ãƒ³è¿½åŠ ï¼ˆç°¡æ˜“ç‰ˆï¼‰
                    zero_in_crop_b = zero_line_b - top_b
                    cv2.line(cropped_b, (0, int(zero_in_crop_b)), (cropped_b.shape[1], int(zero_in_crop_b)), (0, 255, 0), 2)
                    cv2.putText(cropped_b, 'Zero (B)', (10, int(zero_in_crop_b) - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
                    
                    st.image(cropped_b, caption="Bæ¡ˆã«ã‚ˆã‚‹åˆ‡ã‚ŠæŠœã", use_column_width=True)
                    st.info(f"æ¤œå‡ºã‚¹ã‚³ã‚¢: {best_score_b:.3f}, ã‚¼ãƒ­ãƒ©ã‚¤ãƒ³: {zero_line_b}")
                    
                    # ã‚¹ã‚³ã‚¢ã®ã‚°ãƒ©ãƒ•ã‚’è¡¨ç¤ºï¼ˆä¸Šä½10å€‹ï¼‰
                    top_scores = sorted(scores_b, key=lambda x: x[1], reverse=True)[:10]
                    st.caption("ä¸Šä½10å€‹ã®å€™è£œä½ç½®:")
                    for i, (y, score) in enumerate(top_scores):
                        st.caption(f"{i+1}. Y={y}, ã‚¹ã‚³ã‚¢={score:.3f}")
                    
                except Exception as e:
                    st.error(f"Bæ¡ˆã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {str(e)}")
                
                # Cæ¡ˆ: ã‚°ãƒªãƒƒãƒ‰ç›®ç››ã‚Šãƒ™ãƒ¼ã‚¹æ–¹å¼ï¼ˆIMG_0167.PNGå¯¾å¿œï¼‰
                st.markdown("#### Cæ¡ˆ: ã‚°ãƒªãƒƒãƒ‰ç›®ç››ã‚Šãƒ™ãƒ¼ã‚¹æ–¹å¼")
                try:
                    # å³å´ã®ã‚°ãƒªãƒƒãƒ‰ç›®ç››ã‚Šã‚’OCRã§èª­ã¿å–ã‚‹
                    right_area = result['original_image'][:, test_width - 100:]
                    right_gray = cv2.cvtColor(right_area, cv2.COLOR_RGB2GRAY)
                    
                    # OCRã§æ•°å€¤ã‚’æ¤œå‡º
                    import pytesseract
                    ocr_text = pytesseract.image_to_string(right_gray, config='--psm 6 -c tessedit_char_whitelist=0123456789,.-')
                    
                    # æ•°å€¤ã‚’æŠ½å‡º
                    import re
                    numbers = re.findall(r'-?\d+[,.]?\d*', ocr_text.replace(',', ''))
                    detected_scale = None
                    
                    if numbers:
                        # æœ€å¤§å€¤ã‚’æ¨å®šï¼ˆé€šå¸¸ã¯30000, 50000, 80000ãªã©ï¼‰
                        max_num = max([abs(float(n)) for n in numbers if n])
                        if max_num > 20000:
                            detected_scale = max_num
                    
                    # ã‚¹ã‚±ãƒ¼ãƒ«ã«åŸºã¥ã„ã¦ã‚°ãƒ©ãƒ•ã‚¨ãƒªã‚¢ã‚’æ¨å®š
                    if detected_scale:
                        st.caption(f"æ¤œå‡ºã•ã‚ŒãŸã‚¹ã‚±ãƒ¼ãƒ«: Â±{int(detected_scale):,}")
                    else:
                        detected_scale = 30000  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
                        st.caption("ã‚¹ã‚±ãƒ¼ãƒ«æ¤œå‡ºå¤±æ•—ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ä½¿ç”¨")
                    
                    # ã‚°ãƒ©ãƒ•ã‚¨ãƒªã‚¢ã‚’ã‚ªãƒ¬ãƒ³ã‚¸ãƒãƒ¼ã‹ã‚‰æ¨å®š
                    graph_top_c = test_orange_bottom + 30
                    # ã‚¹ã‚±ãƒ¼ãƒ«ã«å¿œã˜ã¦ã‚°ãƒ©ãƒ•ã®é«˜ã•ã‚’èª¿æ•´
                    if detected_scale >= 50000:
                        graph_height = 600  # ã‚ˆã‚Šå¤§ããªã‚°ãƒ©ãƒ•
                    else:
                        graph_height = 493  # æ¨™æº–ã‚µã‚¤ã‚º
                    
                    # ã‚°ãƒ©ãƒ•ã®ä¸­å¤®ã‚’ã‚¼ãƒ­ãƒ©ã‚¤ãƒ³ã¨ã™ã‚‹
                    zero_line_c = graph_top_c + graph_height // 2
                    
                    # åˆ‡ã‚ŠæŠœã
                    top_c = max(0, zero_line_c - graph_height // 2)
                    bottom_c = min(test_height, zero_line_c + graph_height // 2)
                    left_c = 125
                    right_c = test_width - 125
                    
                    cropped_c = result['original_image'][int(top_c):int(bottom_c), int(left_c):int(right_c)].copy()
                    
                    # ã‚°ãƒªãƒƒãƒ‰ãƒ©ã‚¤ãƒ³è¿½åŠ 
                    zero_in_crop_c = zero_line_c - top_c
                    cv2.line(cropped_c, (0, int(zero_in_crop_c)), (cropped_c.shape[1], int(zero_in_crop_c)), (255, 0, 255), 2)
                    cv2.putText(cropped_c, 'Zero (C)', (10, int(zero_in_crop_c) - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 255), 2)
                    
                    st.image(cropped_c, caption="Cæ¡ˆã«ã‚ˆã‚‹åˆ‡ã‚ŠæŠœã", use_column_width=True)
                    st.info(f"ã‚°ãƒ©ãƒ•é«˜ã•: {graph_height}px, ã‚¼ãƒ­ãƒ©ã‚¤ãƒ³: {zero_line_c}")
                    
                except Exception as e:
                    st.error(f"Cæ¡ˆã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {str(e)}")
                
                # Dæ¡ˆ: é©å¿œçš„æ¤œå‡ºæ–¹å¼ï¼ˆè¤‡åˆã‚¢ãƒ—ãƒ­ãƒ¼ãƒï¼‰
                st.markdown("#### Dæ¡ˆ: é©å¿œçš„æ¤œå‡ºæ–¹å¼")
                try:
                    # è¤‡æ•°ã®æ–¹æ³•ã‚’è©¦ã—ã¦æœ€é©ãªã‚‚ã®ã‚’é¸æŠ
                    candidates = []
                    
                    # æ–¹æ³•1: ç¾åœ¨ã®å®Ÿè£…ã¨åŒã˜ï¼ˆæš—ã„ç·šæ¤œå‡ºï¼‰
                    search_start_d = test_orange_bottom + 50
                    search_end_d = min(test_height - 100, test_orange_bottom + 400)
                    
                    best_darkness_score = 0
                    darkness_zero = (search_start_d + search_end_d) // 2
                    
                    for y in range(search_start_d, search_end_d):
                        row = test_gray[y, 100:test_width-100]
                        darkness = 1.0 - (np.mean(row) / 255.0)
                        uniformity = 1.0 - (np.std(row) / 128.0)
                        score = darkness * 0.5 + uniformity * 0.5
                        
                        if score > best_darkness_score:
                            best_darkness_score = score
                            darkness_zero = y
                    
                    if best_darkness_score > 0.3:  # é–¾å€¤
                        candidates.append(('æš—ã„ç·šæ¤œå‡º', darkness_zero, best_darkness_score))
                    
                    # æ–¹æ³•2: ã‚°ãƒ©ãƒ•ç·šã®åˆ†å¸ƒã‹ã‚‰æ¨å®š
                    hsv_d = cv2.cvtColor(result['original_image'], cv2.COLOR_RGB2HSV)
                    # ãƒ”ãƒ³ã‚¯ãƒ»ç´«ç³»ã®è‰²ã‚’æ¤œå‡º
                    pink_mask = cv2.inRange(hsv_d, np.array([140, 50, 50]), np.array([170, 255, 255]))
                    purple_mask = cv2.inRange(hsv_d, np.array([270, 50, 50]), np.array([320, 255, 255]))
                    graph_mask = cv2.bitwise_or(pink_mask, purple_mask)
                    
                    # ã‚°ãƒ©ãƒ•ç·šã®Yåº§æ¨™åˆ†å¸ƒã‚’èª¿ã¹ã‚‹
                    graph_y_coords = []
                    for y in range(search_start_d, search_end_d):
                        if np.sum(graph_mask[y, 100:test_width-100]) > 50:
                            graph_y_coords.append(y)
                    
                    if graph_y_coords:
                        # ã‚°ãƒ©ãƒ•ã®ä¸­å¤®å€¤ã‚’ã‚¼ãƒ­ãƒ©ã‚¤ãƒ³ã¨ã—ã¦æ¨å®š
                        median_y = int(np.median(graph_y_coords))
                        candidates.append(('ã‚°ãƒ©ãƒ•åˆ†å¸ƒ', median_y, 0.5))
                    
                    # æ–¹æ³•3: ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆä½ç½®ï¼ˆã‚°ãƒ©ãƒ•ã‚¨ãƒªã‚¢ã®æ¨å®šä¸­å¤®ï¼‰
                    default_zero = test_orange_bottom + 300
                    candidates.append(('ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ', default_zero, 0.1))
                    
                    # æœ€é©ãªå€™è£œã‚’é¸æŠ
                    if candidates:
                        candidates.sort(key=lambda x: x[2], reverse=True)
                        best_method, zero_line_d, confidence = candidates[0]
                        
                        # åˆ‡ã‚ŠæŠœã
                        top_d = max(0, zero_line_d - 246)
                        bottom_d = min(test_height, zero_line_d + 247)
                        left_d = 125
                        right_d = test_width - 125
                        
                        cropped_d = result['original_image'][int(top_d):int(bottom_d), int(left_d):int(right_d)].copy()
                        
                        # ã‚°ãƒªãƒƒãƒ‰ãƒ©ã‚¤ãƒ³è¿½åŠ 
                        zero_in_crop_d = zero_line_d - top_d
                        cv2.line(cropped_d, (0, int(zero_in_crop_d)), (cropped_d.shape[1], int(zero_in_crop_d)), (0, 255, 255), 2)
                        cv2.putText(cropped_d, 'Zero (D)', (10, int(zero_in_crop_d) - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
                        
                        st.image(cropped_d, caption="Dæ¡ˆã«ã‚ˆã‚‹åˆ‡ã‚ŠæŠœã", use_column_width=True)
                        st.info(f"é¸æŠã•ã‚ŒãŸæ–¹æ³•: {best_method}, ä¿¡é ¼åº¦: {confidence:.2f}")
                        
                        # å…¨å€™è£œã‚’è¡¨ç¤º
                        st.caption("æ¤œå‡ºå€™è£œ:")
                        for method, y, score in candidates:
                            st.caption(f"- {method}: Y={y}, ã‚¹ã‚³ã‚¢={score:.3f}")
                    
                except Exception as e:
                    st.error(f"Dæ¡ˆã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {str(e)}")
                
                # Eæ¡ˆ: ã‚°ãƒ©ãƒ•ç·šãƒ™ãƒ¼ã‚¹æ¤œå‡ºæ–¹å¼ï¼ˆIMG_0164.PNGå¯¾å¿œï¼‰
                st.markdown("#### Eæ¡ˆ: ã‚°ãƒ©ãƒ•ç·šãƒ™ãƒ¼ã‚¹æ¤œå‡ºæ–¹å¼")
                try:
                    # ã‚°ãƒ©ãƒ•ã®è‰²ã‚’æ¤œå‡ºï¼ˆç´«ã€ãƒ”ãƒ³ã‚¯ã€ç·‘ã€é’ãªã©ï¼‰
                    hsv_e = cv2.cvtColor(result['original_image'], cv2.COLOR_RGB2HSV)
                    
                    # è¤‡æ•°ã®è‰²ç¯„å›²ã§ã‚°ãƒ©ãƒ•ç·šã‚’æ¤œå‡º
                    masks = []
                    # ç´«è‰²
                    masks.append(cv2.inRange(hsv_e, np.array([130, 30, 30]), np.array([160, 255, 255])))
                    # ãƒ”ãƒ³ã‚¯è‰²
                    masks.append(cv2.inRange(hsv_e, np.array([160, 30, 30]), np.array([180, 255, 255])))
                    masks.append(cv2.inRange(hsv_e, np.array([0, 30, 30]), np.array([10, 255, 255])))
                    # ç·‘è‰²
                    masks.append(cv2.inRange(hsv_e, np.array([40, 30, 30]), np.array([80, 255, 255])))
                    # é’è‰²
                    masks.append(cv2.inRange(hsv_e, np.array([100, 30, 30]), np.array([130, 255, 255])))
                    
                    # å…¨ã¦ã®ãƒã‚¹ã‚¯ã‚’çµåˆ
                    graph_mask_e = masks[0]
                    for mask in masks[1:]:
                        graph_mask_e = cv2.bitwise_or(graph_mask_e, mask)
                    
                    # ã‚°ãƒ©ãƒ•ç·šãŒå­˜åœ¨ã™ã‚‹Yåº§æ¨™ã‚’åé›†
                    graph_y_positions = []
                    search_start_e = test_orange_bottom + 50
                    search_end_e = test_height - 300
                    
                    for y in range(search_start_e, search_end_e):
                        # ä¸­å¤®éƒ¨åˆ†ã®ã¿ãƒã‚§ãƒƒã‚¯ï¼ˆå·¦å³ã®ä½™ç™½ã‚’é™¤ãï¼‰
                        center_region = graph_mask_e[y, test_width//4:test_width*3//4]
                        if np.sum(center_region) > 100:  # é–¾å€¤
                            graph_y_positions.append(y)
                    
                    if graph_y_positions:
                        # ã‚°ãƒ©ãƒ•ç·šã®æœ€å°Yåº§æ¨™ã¨æœ€å¤§Yåº§æ¨™ã‚’å–å¾—
                        min_y = min(graph_y_positions)
                        max_y = max(graph_y_positions)
                        
                        # ã‚°ãƒ©ãƒ•ãŒã»ã¼æ°´å¹³ãªå ´åˆï¼ˆå¤‰å‹•ãŒå°‘ãªã„ï¼‰
                        if max_y - min_y < 50:
                            # ã‚°ãƒ©ãƒ•ç·šã®å¹³å‡ä½ç½®ã‚’ã‚¼ãƒ­ãƒ©ã‚¤ãƒ³ã¨ã™ã‚‹
                            zero_line_e = int(np.mean(graph_y_positions))
                            detection_method = "æ°´å¹³ã‚°ãƒ©ãƒ•æ¤œå‡º"
                        else:
                            # ã‚°ãƒ©ãƒ•ã«å¤‰å‹•ãŒã‚ã‚‹å ´åˆã¯ã€ã‚°ãƒ©ãƒ•ã®é‡å¿ƒã‚’ã‚¼ãƒ­ãƒ©ã‚¤ãƒ³ã¨ã™ã‚‹
                            weighted_sum = 0
                            weight_total = 0
                            for y in graph_y_positions:
                                weight = np.sum(graph_mask_e[y, test_width//4:test_width*3//4])
                                weighted_sum += y * weight
                                weight_total += weight
                            zero_line_e = int(weighted_sum / weight_total) if weight_total > 0 else int(np.mean(graph_y_positions))
                            detection_method = "ã‚°ãƒ©ãƒ•é‡å¿ƒæ¤œå‡º"
                    else:
                        # ã‚°ãƒ©ãƒ•ç·šãŒæ¤œå‡ºã§ããªã„å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                        # ã‚ªãƒ¬ãƒ³ã‚¸ãƒãƒ¼ã‹ã‚‰ä¸€å®šã®æ¯”ç‡ã§æ¨å®š
                        zero_line_e = test_orange_bottom + int((search_end_e - test_orange_bottom) * 0.4)
                        detection_method = "ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯"
                    
                    # åˆ‡ã‚ŠæŠœã
                    top_e = max(0, zero_line_e - 246)
                    bottom_e = min(test_height, zero_line_e + 247)
                    left_e = 125
                    right_e = test_width - 125
                    
                    cropped_e = result['original_image'][int(top_e):int(bottom_e), int(left_e):int(right_e)].copy()
                    
                    # ã‚°ãƒªãƒƒãƒ‰ãƒ©ã‚¤ãƒ³è¿½åŠ 
                    zero_in_crop_e = zero_line_e - top_e
                    cv2.line(cropped_e, (0, int(zero_in_crop_e)), (cropped_e.shape[1], int(zero_in_crop_e)), (255, 255, 0), 2)
                    cv2.putText(cropped_e, 'Zero (E)', (10, int(zero_in_crop_e) - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)
                    
                    # ã‚°ãƒ©ãƒ•ç·šã®æ¤œå‡ºçµæœã‚’å¯è¦–åŒ–ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
                    if graph_y_positions:
                        for y in [min(graph_y_positions), max(graph_y_positions)]:
                            y_in_crop = y - top_e
                            if 0 <= y_in_crop < cropped_e.shape[0]:
                                cv2.line(cropped_e, (0, int(y_in_crop)), (50, int(y_in_crop)), (0, 255, 255), 1)
                    
                    st.image(cropped_e, caption="Eæ¡ˆã«ã‚ˆã‚‹åˆ‡ã‚ŠæŠœã", use_column_width=True)
                    st.info(f"æ¤œå‡ºæ–¹æ³•: {detection_method}, ã‚¼ãƒ­ãƒ©ã‚¤ãƒ³: {zero_line_e}")
                    if graph_y_positions:
                        st.caption(f"ã‚°ãƒ©ãƒ•æ¤œå‡ºç¯„å›²: Y={min(graph_y_positions)}ã€œ{max(graph_y_positions)} (å¹…: {max(graph_y_positions)-min(graph_y_positions)}px)")
                    
                except Exception as e:
                    st.error(f"Eæ¡ˆã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {str(e)}")
                
                # Fæ¡ˆ: å›ºå®šä½ç½®æ–¹å¼ï¼ˆIMG_0xxx.PNGå°‚ç”¨ï¼‰
                st.markdown("#### Fæ¡ˆ: å›ºå®šä½ç½®æ–¹å¼")
                try:
                    # IMG_0xxx.PNGã‚·ãƒªãƒ¼ã‚ºã®ç‰¹å¾´ã‚’æ¤œå‡º
                    is_img_series = False
                    
                    # ç‰¹å¾´1: ç”»é¢ã‚µã‚¤ã‚ºãŒç‰¹å®šã®å€¤
                    if test_height > 2400 and test_height < 2700:
                        # ç‰¹å¾´2: ã‚ªãƒ¬ãƒ³ã‚¸ãƒãƒ¼ã®ä½ç½®ãŒç‰¹å®šã®ç¯„å›²
                        if test_orange_bottom > 650 and test_orange_bottom < 750:
                            # ç‰¹å¾´3: èƒŒæ™¯è‰²ãŒã‚°ãƒ¬ãƒ¼ç³»
                            bg_sample = test_gray[test_orange_bottom + 100:test_orange_bottom + 200, test_width//4:test_width*3//4]
                            bg_mean = np.mean(bg_sample)
                            if bg_mean > 200 and bg_mean < 240:
                                is_img_series = True
                    
                    if is_img_series:
                        # IMG_0xxx.PNGç”¨ã®å›ºå®šä½ç½®
                        # å®Ÿéš›ã®è¦³å¯Ÿã‹ã‚‰ã€ã‚¼ãƒ­ãƒ©ã‚¤ãƒ³ã¯ç´„Y=1350ä»˜è¿‘ã«ã‚ã‚‹
                        zero_line_f = test_orange_bottom + 650  # ã‚ªãƒ¬ãƒ³ã‚¸ãƒãƒ¼ã‹ã‚‰650pxä¸‹
                        detection_info = "IMG_0xxx.PNGæ¤œå‡º"
                    else:
                        # é€šå¸¸ã®ç”»åƒç”¨ï¼ˆç¾åœ¨ã®å®Ÿè£…ã¨åŒã˜ï¼‰
                        search_start_f = test_orange_bottom + 50
                        search_end_f = min(test_height - 100, test_orange_bottom + 400)
                        
                        best_score_f = 0
                        zero_line_f = (search_start_f + search_end_f) // 2
                        
                        for y in range(search_start_f, search_end_f):
                            row = test_gray[y, 100:test_width-100]
                            darkness = 1.0 - (np.mean(row) / 255.0)
                            uniformity = 1.0 - (np.std(row) / 128.0)
                            score = darkness * 0.5 + uniformity * 0.5
                            
                            if score > best_score_f:
                                best_score_f = score
                                zero_line_f = y
                        
                        detection_info = f"é€šå¸¸æ¤œå‡ºï¼ˆã‚¹ã‚³ã‚¢: {best_score_f:.3f}ï¼‰"
                    
                    # åˆ‡ã‚ŠæŠœã
                    top_f = max(0, zero_line_f - 246)
                    bottom_f = min(test_height, zero_line_f + 247)
                    left_f = 125
                    right_f = test_width - 125
                    
                    cropped_f = result['original_image'][int(top_f):int(bottom_f), int(left_f):int(right_f)].copy()
                    
                    # ã‚°ãƒªãƒƒãƒ‰ãƒ©ã‚¤ãƒ³è¿½åŠ 
                    zero_in_crop_f = zero_line_f - top_f
                    cv2.line(cropped_f, (0, int(zero_in_crop_f)), (cropped_f.shape[1], int(zero_in_crop_f)), (255, 0, 255), 2)
                    cv2.putText(cropped_f, 'Zero (F)', (10, int(zero_in_crop_f) - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 255), 2)
                    
                    # è¿½åŠ ã®ã‚°ãƒªãƒƒãƒ‰ãƒ©ã‚¤ãƒ³ï¼ˆÂ±10000ï¼‰
                    scale_f = 122  # å›ºå®šã‚¹ã‚±ãƒ¼ãƒ«
                    for val, label in [(10000, '+10k'), (-10000, '-10k')]:
                        y_offset = int(val / scale_f)
                        y_pos = int(zero_in_crop_f - y_offset)
                        if 0 < y_pos < cropped_f.shape[0]:
                            cv2.line(cropped_f, (0, y_pos), (cropped_f.shape[1], y_pos), (200, 200, 200), 1)
                            cv2.putText(cropped_f, label, (10, y_pos - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (128, 128, 128), 1)
                    
                    st.image(cropped_f, caption="Fæ¡ˆã«ã‚ˆã‚‹åˆ‡ã‚ŠæŠœã", use_column_width=True)
                    st.info(f"{detection_info}, ã‚¼ãƒ­ãƒ©ã‚¤ãƒ³: {zero_line_f}")
                    
                    if is_img_series:
                        st.caption("IMG_0xxx.PNGã‚·ãƒªãƒ¼ã‚ºã¨åˆ¤å®šã•ã‚Œã¾ã—ãŸ")
                        st.caption(f"èƒŒæ™¯è¼åº¦: {bg_mean:.1f}, ç”»åƒé«˜ã•: {test_height}px")
                    
                except Exception as e:
                    st.error(f"Fæ¡ˆã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {str(e)}")
                
                # Gæ¡ˆ: IMG_0xxx.PNGå°‚ç”¨æ‹¡å¼µæ¤œç´¢æ–¹å¼
                st.markdown("#### Gæ¡ˆ: IMG_0xxx.PNGå°‚ç”¨æ‹¡å¼µæ¤œç´¢æ–¹å¼")
                try:
                    # IMG_0xxx.PNGã‚·ãƒªãƒ¼ã‚ºã®æ¤œå‡º
                    is_img_series_g = False
                    if test_height > 2400 and test_height < 2700:
                        if test_orange_bottom < 1000:  # ã‚ªãƒ¬ãƒ³ã‚¸ãƒãƒ¼ãŒä¸Šéƒ¨ã«ã‚ã‚‹
                            # èƒŒæ™¯è‰²ãƒã‚§ãƒƒã‚¯
                            bg_sample_g = test_gray[test_orange_bottom + 100:test_orange_bottom + 200, test_width//4:test_width*3//4]
                            bg_mean_g = np.mean(bg_sample_g)
                            if bg_mean_g > 200 and bg_mean_g < 240:
                                is_img_series_g = True
                    
                    if is_img_series_g:
                        # IMG_0xxx.PNGç”¨ã®æ‹¡å¼µæ¤œç´¢ç¯„å›²
                        search_start_g = test_orange_bottom + 200  # ã‚ˆã‚Šä¸‹ã‹ã‚‰é–‹å§‹
                        search_end_g = min(test_height - 300, test_orange_bottom + 800)  # ã‚ˆã‚Šåºƒã„ç¯„å›²
                        detection_info_g = "IMG_0xxx.PNGæ¤œå‡ºï¼ˆæ‹¡å¼µç¯„å›²ï¼‰"
                    else:
                        # é€šå¸¸ã®æ¤œç´¢ç¯„å›²
                        search_start_g = test_orange_bottom + 50
                        search_end_g = min(test_height - 100, test_orange_bottom + 400)
                        detection_info_g = "é€šå¸¸æ¤œå‡º"
                    
                    best_score_g = 0
                    zero_line_g = (search_start_g + search_end_g) // 2
                    scores_g = []
                    
                    for y in range(search_start_g, search_end_g):
                        row_g = test_gray[y, 100:test_width-100]
                        darkness_g = 1.0 - (np.mean(row_g) / 255.0)
                        uniformity_g = 1.0 - (np.std(row_g) / 128.0)
                        score_g = darkness_g * 0.5 + uniformity_g * 0.5
                        
                        scores_g.append((y, score_g))
                        
                        if score_g > best_score_g:
                            best_score_g = score_g
                            zero_line_g = y
                    
                    # åˆ‡ã‚ŠæŠœã
                    top_g = max(0, zero_line_g - 246)
                    bottom_g = min(test_height, zero_line_g + 247)
                    left_g = 125
                    right_g = test_width - 125
                    
                    cropped_g = result['original_image'][int(top_g):int(bottom_g), int(left_g):int(right_g)].copy()
                    
                    # ã‚°ãƒªãƒƒãƒ‰ãƒ©ã‚¤ãƒ³è¿½åŠ 
                    zero_in_crop_g = zero_line_g - top_g
                    cv2.line(cropped_g, (0, int(zero_in_crop_g)), (cropped_g.shape[1], int(zero_in_crop_g)), (0, 255, 128), 2)
                    cv2.putText(cropped_g, 'Zero (G)', (10, int(zero_in_crop_g) - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 128), 2)
                    
                    st.image(cropped_g, caption="Gæ¡ˆã«ã‚ˆã‚‹åˆ‡ã‚ŠæŠœã", use_column_width=True)
                    st.info(f"{detection_info_g}, ã‚¼ãƒ­ãƒ©ã‚¤ãƒ³: {zero_line_g}, ã‚¹ã‚³ã‚¢: {best_score_g:.3f}")
                    st.caption(f"æ¤œç´¢ç¯„å›²: Y={search_start_g}ã€œ{search_end_g} (å¹…: {search_end_g-search_start_g}px)")
                    
                    if is_img_series_g:
                        # ä¸Šä½ã‚¹ã‚³ã‚¢ã‚’è¡¨ç¤º
                        top_scores_g = sorted(scores_g, key=lambda x: x[1], reverse=True)[:5]
                        st.caption("ä¸Šä½5å€‹ã®å€™è£œ:")
                        for i, (y, score) in enumerate(top_scores_g):
                            st.caption(f"{i+1}. Y={y}, ã‚¹ã‚³ã‚¢={score:.3f}")
                    
                except Exception as e:
                    st.error(f"Gæ¡ˆã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {str(e)}")
                
                # Hæ¡ˆ: Gæ¡ˆæ”¹è‰¯ç‰ˆï¼ˆã‚¹ã‚±ãƒ¼ãƒ«èª¿æ•´ä»˜ãï¼‰
                st.markdown("#### Hæ¡ˆ: Gæ¡ˆæ”¹è‰¯ç‰ˆï¼ˆã‚¹ã‚±ãƒ¼ãƒ«èª¿æ•´ä»˜ãï¼‰")
                try:
                    # IMG_0xxx.PNGã‚·ãƒªãƒ¼ã‚ºã®æ¤œå‡º
                    is_img_series_h = False
                    if test_height > 2400 and test_height < 2700:
                        if test_orange_bottom < 1000:  # ã‚ªãƒ¬ãƒ³ã‚¸ãƒãƒ¼ãŒä¸Šéƒ¨ã«ã‚ã‚‹
                            # èƒŒæ™¯è‰²ãƒã‚§ãƒƒã‚¯
                            bg_sample_h = test_gray[test_orange_bottom + 100:test_orange_bottom + 200, test_width//4:test_width*3//4]
                            bg_mean_h = np.mean(bg_sample_h)
                            if bg_mean_h > 200 and bg_mean_h < 240:
                                is_img_series_h = True
                    
                    if is_img_series_h:
                        # IMG_0xxx.PNGç”¨ã®æ‹¡å¼µæ¤œç´¢ç¯„å›²
                        search_start_h = test_orange_bottom + 200
                        search_end_h = min(test_height - 300, test_orange_bottom + 800)
                        detection_info_h = "IMG_0xxx.PNGæ¤œå‡ºï¼ˆæ‹¡å¼µç¯„å›²ï¼‰"
                        # IMG_0xxx.PNGç”¨ã®ã‚¹ã‚±ãƒ¼ãƒ«ï¼ˆÂ±50000ï¼‰
                        scale_h = 50000 / 408  # ç´„122.5ç‰/pxï¼ˆã‚°ãƒ©ãƒ•é«˜ã•816pxã§Â±50000ï¼‰
                        crop_top_offset = 408  # ä¸Šæ–¹å‘ã®åˆ‡ã‚ŠæŠœãã‚µã‚¤ã‚º
                        crop_bottom_offset = 408  # ä¸‹æ–¹å‘ã®åˆ‡ã‚ŠæŠœãã‚µã‚¤ã‚º
                    else:
                        # é€šå¸¸ã®æ¤œç´¢ç¯„å›²
                        search_start_h = test_orange_bottom + 50
                        search_end_h = min(test_height - 100, test_orange_bottom + 400)
                        detection_info_h = "é€šå¸¸æ¤œå‡º"
                        # é€šå¸¸ã®ã‚¹ã‚±ãƒ¼ãƒ«ï¼ˆÂ±30000ï¼‰
                        scale_h = 30000 / 246  # ç´„122ç‰/px
                        crop_top_offset = 246
                        crop_bottom_offset = 247
                    
                    best_score_h = 0
                    zero_line_h = (search_start_h + search_end_h) // 2
                    
                    for y in range(search_start_h, search_end_h):
                        row_h = test_gray[y, 100:test_width-100]
                        darkness_h = 1.0 - (np.mean(row_h) / 255.0)
                        uniformity_h = 1.0 - (np.std(row_h) / 128.0)
                        score_h = darkness_h * 0.5 + uniformity_h * 0.5
                        
                        if score_h > best_score_h:
                            best_score_h = score_h
                            zero_line_h = y
                    
                    # åˆ‡ã‚ŠæŠœãï¼ˆã‚¹ã‚±ãƒ¼ãƒ«ã«å¿œã˜ãŸã‚µã‚¤ã‚ºï¼‰
                    top_h = max(0, zero_line_h - crop_top_offset)
                    bottom_h = min(test_height, zero_line_h + crop_bottom_offset)
                    left_h = 125
                    right_h = test_width - 125
                    
                    cropped_h = result['original_image'][int(top_h):int(bottom_h), int(left_h):int(right_h)].copy()
                    
                    # ã‚°ãƒªãƒƒãƒ‰ãƒ©ã‚¤ãƒ³è¿½åŠ 
                    zero_in_crop_h = zero_line_h - top_h
                    cv2.line(cropped_h, (0, int(zero_in_crop_h)), (cropped_h.shape[1], int(zero_in_crop_h)), (128, 255, 128), 2)
                    cv2.putText(cropped_h, 'Zero (H)', (10, int(zero_in_crop_h) - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (128, 255, 128), 2)
                    
                    # ã‚¹ã‚±ãƒ¼ãƒ«ã«å¿œã˜ãŸã‚°ãƒªãƒƒãƒ‰ãƒ©ã‚¤ãƒ³
                    if is_img_series_h:
                        # Â±50000, Â±25000ã®ãƒ©ã‚¤ãƒ³
                        grid_values = [(50000, '+50k'), (25000, '+25k'), (-25000, '-25k'), (-50000, '-50k')]
                    else:
                        # Â±30000, Â±10000ã®ãƒ©ã‚¤ãƒ³
                        grid_values = [(30000, '+30k'), (10000, '+10k'), (-10000, '-10k'), (-30000, '-30k')]
                    
                    for val, label in grid_values:
                        y_offset = int(val / scale_h)
                        y_pos = int(zero_in_crop_h - y_offset)
                        if 0 < y_pos < cropped_h.shape[0]:
                            cv2.line(cropped_h, (0, y_pos), (cropped_h.shape[1], y_pos), (200, 200, 200), 1)
                            cv2.putText(cropped_h, label, (10, y_pos - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (128, 128, 128), 1)
                    
                    st.image(cropped_h, caption="Hæ¡ˆã«ã‚ˆã‚‹åˆ‡ã‚ŠæŠœã", use_column_width=True)
                    st.info(f"{detection_info_h}, ã‚¼ãƒ­ãƒ©ã‚¤ãƒ³: {zero_line_h}, ã‚¹ã‚³ã‚¢: {best_score_h:.3f}")
                    st.caption(f"ã‚¹ã‚±ãƒ¼ãƒ«: Â±{int(scale_h * crop_top_offset):,}, åˆ‡ã‚ŠæŠœãã‚µã‚¤ã‚º: {int(bottom_h - top_h)}px")
                    
                except Exception as e:
                    st.error(f"Hæ¡ˆã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {str(e)}")
            
            # æˆåŠŸæ™‚ã¯çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤ºï¼ˆè§£æçµæœã®ä¸‹ã«ç¸¦ã«ä¸¦ã¹ã‚‹ï¼‰
            if result['success']:
                # çµ±è¨ˆæƒ…å ±ã‚’ã‚«ãƒ¼ãƒ‰é¢¨ã«è¡¨ç¤º
                st.markdown("""
                <style>
                .stat-card {
                    background-color: #f0f2f6;
                    padding: 15px;
                    border-radius: 10px;
                    margin-top: 10px;
                }
                .stat-item {
                    display: flex;
                    justify-content: space-between;
                    padding: 5px 0;
                    border-bottom: 1px solid #e0e0e0;
                }
                .stat-item:last-child {
                    border-bottom: none;
                }
                .stat-label {
                    color: #666;
                    font-weight: 500;
                }
                .stat-value {
                    font-weight: bold;
                    color: #333;
                }
                .stat-value.positive {
                    color: #28a745;
                }
                .stat-value.negative {
                    color: #dc3545;
                }
                .stat-value.zero {
                    color: #6c757d;
                }
                </style>
                """, unsafe_allow_html=True)
                
                # å€¤ã«å¿œã˜ã¦è‰²åˆ†ã‘ã™ã‚‹ãŸã‚ã®ã‚¯ãƒ©ã‚¹ã‚’æ±ºå®š
                def get_value_class(val):
                    if val > 0:
                        return "positive"
                    elif val < 0:
                        return "negative"
                    else:
                        return "zero"
                
                first_hit_text = f"{result['first_hit_val']:,}ç‰" if result['first_hit_val'] is not None else "ãªã—"
                first_hit_class = get_value_class(result['first_hit_val']) if result['first_hit_val'] is not None else ""
                
                st.markdown(f"""
                <div class="stat-card">
                    <div class="stat-item">
                        <span class="stat-label">ğŸ“ˆ æœ€é«˜å€¤</span>
                        <span class="stat-value {get_value_class(result['max_val'])}">{result['max_val']:,}ç‰</span>
                    </div>
                    <div class="stat-item">
                        <span class="stat-label">ğŸ“‰ æœ€ä½å€¤</span>
                        <span class="stat-value {get_value_class(result['min_val'])}">{result['min_val']:,}ç‰</span>
                    </div>
                    <div class="stat-item">
                        <span class="stat-label">ğŸ¯ ç¾åœ¨å€¤</span>
                        <span class="stat-value {get_value_class(result['current_val'])}">{result['current_val']:,}ç‰</span>
                    </div>
                    <div class="stat-item">
                        <span class="stat-label">ğŸ° åˆå½“ãŸã‚Š</span>
                        <span class="stat-value {first_hit_class}">{first_hit_text}</span>
                    </div>
                </div>
                """, unsafe_allow_html=True)
                
                # OCRãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã¯è¡¨ç¤º
                if result.get('ocr_data') and any(result['ocr_data'].values()):
                    ocr = result['ocr_data']
                    st.markdown("""
                    <style>
                    .ocr-card {
                        background-color: #e8f4f8;
                        padding: 15px;
                        border-radius: 10px;
                        margin-top: 10px;
                        border: 1px solid #bee5eb;
                    }
                    .ocr-title {
                        color: #17a2b8;
                        font-weight: bold;
                        margin-bottom: 10px;
                    }
                    .ocr-item {
                        display: flex;
                        justify-content: space-between;
                        padding: 5px 0;
                        border-bottom: 1px solid #d1ecf1;
                    }
                    .ocr-item:last-child {
                        border-bottom: none;
                    }
                    .ocr-label {
                        color: #0c5460;
                        font-weight: 500;
                    }
                    .ocr-value {
                        font-weight: bold;
                        color: #0c5460;
                    }
                    </style>
                    """, unsafe_allow_html=True)
                    
                    ocr_html = '<div class="ocr-card"><div class="ocr-title">ğŸ“± site7ãƒ‡ãƒ¼ã‚¿</div>'
                    
                    # å°ç•ªå·
                    if ocr.get('machine_number'):
                        ocr_html += f'<div class="ocr-item"><span class="ocr-label">ğŸ”¢ å°ç•ªå·</span><span class="ocr-value">{ocr["machine_number"]}</span></div>'
                    
                    # éŠæŠ€ãƒ‡ãƒ¼ã‚¿
                    if ocr.get('total_start'):
                        ocr_html += f'<div class="ocr-item"><span class="ocr-label">ğŸ² ç´¯è¨ˆã‚¹ã‚¿ãƒ¼ãƒˆ</span><span class="ocr-value">{ocr["total_start"]}</span></div>'
                    if ocr.get('jackpot_count'):
                        ocr_html += f'<div class="ocr-item"><span class="ocr-label">ğŸŠ å¤§å½“ã‚Šå›æ•°</span><span class="ocr-value">{ocr["jackpot_count"]}å›</span></div>'
                    if ocr.get('first_hit_count'):
                        ocr_html += f'<div class="ocr-item"><span class="ocr-label">ğŸ¯ åˆå½“ã‚Šå›æ•°</span><span class="ocr-value">{ocr["first_hit_count"]}å›</span></div>'
                    if ocr.get('current_start'):
                        ocr_html += f'<div class="ocr-item"><span class="ocr-label">ğŸ“Š ã‚¹ã‚¿ãƒ¼ãƒˆ</span><span class="ocr-value">{ocr["current_start"]}</span></div>'
                    if ocr.get('jackpot_probability'):
                        ocr_html += f'<div class="ocr-item"><span class="ocr-label">ğŸ“ˆ å¤§å½“ã‚Šç¢ºç‡</span><span class="ocr-value">{ocr["jackpot_probability"]}</span></div>'
                    if ocr.get('max_payout'):
                        ocr_html += f'<div class="ocr-item"><span class="ocr-label">ğŸ’° æœ€é«˜å‡ºç‰</span><span class="ocr-value">{ocr["max_payout"]}ç‰</span></div>'
                    
                    ocr_html += '</div>'
                    st.markdown(ocr_html, unsafe_allow_html=True)
                
            else:
                st.warning("âš ï¸ ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ã‚’æ¤œå‡ºã§ãã¾ã›ã‚“ã§ã—ãŸ")
            
            # åŒºåˆ‡ã‚Šç·šï¼ˆå„åˆ—å†…ã§ï¼‰
            if idx < len(analysis_results) - 2:
                st.markdown("---")
        
    # ã‚µãƒãƒªãƒ¼æƒ…å ±
    st.markdown("### ğŸ“‹ è§£æã‚µãƒãƒªãƒ¼")
    
    success_count = sum(1 for r in analysis_results if r['success'])
    st.info(f"ğŸ“ˆ ç·ç”»åƒæ•°: {len(analysis_results)}æš | âœ… æˆåŠŸ: {success_count}æš | âš ï¸ å¤±æ•—: {len(analysis_results) - success_count}æš")
    
    
    # çµæœã‚’è¡¨å½¢å¼ã§è¡¨ç¤º
    st.markdown("### ğŸ“Š è§£æçµæœï¼ˆè¡¨å½¢å¼ï¼‰")
    
    # çµ±è¨ˆæƒ…å ±ã‚’è¨ˆç®—ã—ã¦è¡¨ç¤º
    if analysis_results:
        success_results = [r for r in analysis_results if r.get('success')]
        if success_results:
            # çµ±è¨ˆæƒ…å ±ã®è¨ˆç®—
            total_balance = sum(r['current_val'] for r in success_results)
            total_balance_yen = total_balance * 4
            avg_balance = total_balance / len(success_results)
            avg_balance_yen = avg_balance * 4
            max_result = max(success_results, key=lambda x: x['current_val'])
            min_result = min(success_results, key=lambda x: x['current_val'])
            
            # çµ±è¨ˆæƒ…å ±ã‚’3åˆ—ã§è¡¨ç¤º
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric(
                    "åˆè¨ˆåæ”¯",
                    f"{total_balance_yen:+,}å††",
                    f"{total_balance:+,}ç‰"
                )
            
            with col2:
                st.metric(
                    "å¹³å‡åæ”¯",
                    f"{avg_balance_yen:+,.0f}å††",
                    f"{avg_balance:+,.0f}ç‰"
                )
            
            with col3:
                st.metric(
                    "è§£æå°æ•°",
                    f"{len(success_results)}å°",
                    f"æˆåŠŸç‡ {len(success_results)/len(analysis_results)*100:.0f}%"
                )
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ä½œæˆ
    table_data = []
    for idx, result in enumerate(analysis_results):
        if result.get('success'):
            row = {
                'ç•ªå·': idx + 1,
                'ãƒ•ã‚¡ã‚¤ãƒ«å': result['name'],
                'æœ€é«˜å€¤': f"{result['max_val']:,}",
                'æœ€ä½å€¤': f"{result['min_val']:,}",
                'ç¾åœ¨å€¤': f"{result['current_val']:,}",
                'åˆå½“ãŸã‚Š': f"{result['first_hit_val']:,}" if result['first_hit_val'] is not None else "-",
                'åæ”¯(å††)': f"{result['current_val'] * 4:+,}",
            }
            
            # OCRãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã¯è¿½åŠ 
            if result.get('ocr_data'):
                ocr = result['ocr_data']
                row.update({
                    'ç´¯è¨ˆã‚¹ã‚¿ãƒ¼ãƒˆ': ocr.get('total_start', '-'),
                    'å¤§å½“ã‚Šå›æ•°': f"{ocr.get('jackpot_count')}å›" if ocr.get('jackpot_count') else '-',
                    'åˆå½“ã‚Šå›æ•°': f"{ocr.get('first_hit_count')}å›" if ocr.get('first_hit_count') else '-',
                    'ç¢ºç‡': ocr.get('jackpot_probability', '-'),
                    'æœ€é«˜å‡ºç‰': f"{ocr.get('max_payout')}ç‰" if ocr.get('max_payout') else '-',
                })
            
            table_data.append(row)
    
    if table_data:
        df = pd.DataFrame(table_data)
        
        # è¡¨ç¤ºã™ã‚‹åˆ—ã‚’é¸æŠï¼ˆå­˜åœ¨ã™ã‚‹åˆ—ã®ã¿ï¼‰
        display_columns = ['ç•ªå·', 'ãƒ•ã‚¡ã‚¤ãƒ«å', 'ç´¯è¨ˆã‚¹ã‚¿ãƒ¼ãƒˆ', 'å¤§å½“ã‚Šå›æ•°', 
                          'æœ€é«˜å€¤', 'æœ€ä½å€¤', 'ç¾åœ¨å€¤', 'åˆå½“ãŸã‚Š', 'åæ”¯(å††)']
        display_columns = [col for col in display_columns if col in df.columns]
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’è¡¨ç¤º
        st.dataframe(
            df[display_columns],
            use_container_width=True,
            hide_index=True
        )
        
        # CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        csv = df.to_csv(index=False, encoding='utf-8-sig')
        st.download_button(
            label="ğŸ“¥ CSV ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=csv,
            file_name=f"pachi_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
            mime="text/csv",
            help="Excelç­‰ã§é–‹ã‘ã‚‹CSVå½¢å¼ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"
        )
    
else:
    # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å‰ã®è¡¨ç¤º
    st.info("ğŸ‘† ä¸Šã®ãƒœã‚¿ãƒ³ã‹ã‚‰ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")
    
    # ä½¿ã„æ–¹
    with st.expander("ğŸ’¡ ä½¿ã„æ–¹"):
        st.markdown("""
            1. **ã€ŒBrowse filesã€ãƒœã‚¿ãƒ³**ã‚’ã‚¯ãƒªãƒƒã‚¯
            2. **ã‚°ãƒ©ãƒ•ç”»åƒã‚’é¸æŠ**ï¼ˆè¤‡æ•°é¸æŠå¯ï¼‰
            3. **è‡ªå‹•çš„ã«åˆ‡ã‚ŠæŠœãã¨è§£æãŒå®Ÿè¡Œã•ã‚Œã¾ã™**
            
            å¯¾å¿œãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ:
            - JPG/JPEG
            - PNG
            """)

# æ©Ÿèƒ½ç´¹ä»‹
st.markdown("---")
st.markdown("### ğŸš€ ä¸»ãªæ©Ÿèƒ½")
col1, col2, col3 = st.columns(3)
with col1:
    st.markdown("#### ğŸ“ˆ AIã‚°ãƒ©ãƒ•è§£æ")
    st.markdown("AIãŒã‚°ãƒ©ãƒ•ã‚’è‡ªå‹•èªè­˜ã—ã€æ­£ç¢ºãªãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º")
with col2:
    st.markdown("#### âœ‚ï¸ è‡ªå‹•åˆ‡ã‚ŠæŠœã")
    st.markdown("ã‚°ãƒ©ãƒ•é ˜åŸŸã‚’è‡ªå‹•æ¤œå‡ºã—ã¦æœ€é©åŒ–")
with col3:
    st.markdown("#### ğŸ’¡ çµ±è¨ˆåˆ†æ")
    st.markdown("æœ€é«˜å€¤ã€æœ€ä½å€¤ã€åˆå½“ãŸã‚Šç­‰ã‚’ç¬æ™‚ã«è¨ˆç®—")

# æ“ä½œãƒãƒ‹ãƒ¥ã‚¢ãƒ«
st.markdown("---")
st.markdown("### ğŸ“– æ“ä½œãƒãƒ‹ãƒ¥ã‚¢ãƒ«")
with st.expander("ä½¿ã„æ–¹ã¨æ³¨æ„äº‹é …ã‚’ç¢ºèªã™ã‚‹"):
    st.markdown("""
    #### ğŸ¯ æœ¬ãƒ„ãƒ¼ãƒ«ã«ã¤ã„ã¦
    ã“ã®ãƒ„ãƒ¼ãƒ«ã¯ **[site7](https://m.site777.jp/)ã®ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿å°‚ç”¨** ã®è§£æãƒ„ãƒ¼ãƒ«ã§ã™ã€‚  
    ãã‚Œä»¥å¤–ã®ã‚µã‚¤ãƒˆã®ã‚°ãƒ©ãƒ•ã«ã¯å¯¾å¿œã—ã¦ã„ã¾ã›ã‚“ã€‚
    
    #### ğŸ“‹ ä½¿ã„æ–¹
    1. **ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰**
       - ã€ŒBrowse filesã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯
       - site7ã®ã‚°ãƒ©ãƒ•ç”»åƒã‚’é¸æŠï¼ˆè¤‡æ•°é¸æŠå¯ï¼‰
       - å¯¾å¿œå½¢å¼ï¼šJPG/JPEGã€PNG
    
    2. **è‡ªå‹•è§£æ**
       - ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¾Œã€è‡ªå‹•çš„ã«è§£æãŒé–‹å§‹ã•ã‚Œã¾ã™
       - ã‚°ãƒ©ãƒ•ã®0ãƒ©ã‚¤ãƒ³ã‚’æ¤œå‡ºã—ã€é©åˆ‡ãªç¯„å›²ã§åˆ‡ã‚ŠæŠœãã¾ã™
       - ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºã—ã€çµ±è¨ˆæƒ…å ±ã‚’è¨ˆç®—ã—ã¾ã™
    
    3. **çµæœã®ç¢ºèª**
       - è§£æçµæœã¯2åˆ—ã§è¡¨ç¤ºã•ã‚Œã¾ã™ï¼ˆãƒ¢ãƒã‚¤ãƒ«ã§ã¯1åˆ—ï¼‰
       - å„çµæœã«ã¯ä»¥ä¸‹ãŒå«ã¾ã‚Œã¾ã™ï¼š
         - è§£ææ¸ˆã¿ã‚°ãƒ©ãƒ•ç”»åƒï¼ˆç·‘è‰²ã®ãƒ©ã‚¤ãƒ³ï¼‰
         - çµ±è¨ˆæƒ…å ±ï¼ˆæœ€é«˜å€¤ã€æœ€ä½å€¤ã€ç¾åœ¨å€¤ã€åˆå½“ãŸã‚Šï¼‰
         - å…ƒç”»åƒï¼ˆæŠ˜ã‚ŠãŸãŸã¿å¯èƒ½ï¼‰
    
    #### âš ï¸ æ³¨æ„äº‹é …
    - **site7å°‚ç”¨**ï¼šä»–ã®ã‚µã‚¤ãƒˆã®ã‚°ãƒ©ãƒ•ã¯æ­£ã—ãè§£æã§ãã¾ã›ã‚“
    - **ç”»åƒå“è³ª**ï¼šé®®æ˜ãªç”»åƒã»ã©ç²¾åº¦ãŒå‘ä¸Šã—ã¾ã™
    - **ã‚°ãƒ©ãƒ•å…¨ä½“**ï¼šã‚°ãƒ©ãƒ•ã®ä¸Šä¸‹ãŒåˆ‡ã‚Œã¦ã„ãªã„ç”»åƒã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„
    - **åˆå½“ãŸã‚Šæ¤œå‡º**ï¼šãƒã‚¤ãƒŠã‚¹å€¤ã‹ã‚‰ã®100ç‰ä»¥ä¸Šã®æ€¥ä¸Šæ˜‡ã‚’æ¤œå‡ºã—ã¾ã™
    
    #### ğŸ”§ æŠ€è¡“ä»•æ§˜
    - 0ãƒ©ã‚¤ãƒ³åŸºæº–ï¼šä¸Š246pxã€ä¸‹247pxï¼ˆÂ±30,000ç‰ç›¸å½“ï¼‰
    - ã‚¹ã‚±ãƒ¼ãƒ«ï¼š120ç‰/ãƒ”ã‚¯ã‚»ãƒ«
    - å·¦å³ä½™ç™½ï¼š125pxé™¤å¤–
    """)

# ãƒ•ãƒƒã‚¿ãƒ¼
st.markdown("---")
st.markdown(f"""
ğŸ° ãƒ‘ãƒãƒ³ã‚³ã‚°ãƒ©ãƒ•è§£æã‚·ã‚¹ãƒ†ãƒ  v2.0  
æ›´æ–°æ—¥: {datetime.now().strftime('%Y/%m/%d')}  
Produced by [PPã‚¿ã‚¦ãƒ³](https://pp-town.com/)  
Created by [fivenine-design.com](https://fivenine-design.com)
""")