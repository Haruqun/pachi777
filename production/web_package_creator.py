#!/usr/bin/env python3
"""
Webé…ä¿¡ç”¨ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ä½œæˆãƒ„ãƒ¼ãƒ«
HTMLãƒ¬ãƒãƒ¼ãƒˆã¨é–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ZIPã§ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸åŒ–
"""

import zipfile
import glob
from pathlib import Path
import shutil
import os
from datetime import datetime
import json

def create_web_package():
    """Webé…ä¿¡ç”¨ZIPãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ä½œæˆ"""
    
    print("ğŸ“¦ Webé…ä¿¡ç”¨ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ä½œæˆé–‹å§‹")
    print("=" * 60)
    
    # æœ€æ–°ã®HTMLãƒ¬ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
    html_files = glob.glob("reports/*/html/professional_graph_report_*.html")
    
    if not html_files:
        print("âŒ professional_graph_report_*.html ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return None
    
    # æœ€æ–°ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ
    latest_html = max(html_files, key=lambda x: Path(x).stat().st_mtime)
    print(f"ğŸ“ ãƒ¡ã‚¤ãƒ³HTMLãƒ•ã‚¡ã‚¤ãƒ«: {latest_html}")
    
    # ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸åç”Ÿæˆ
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    package_name = f"pptown_graph_analysis_report_{timestamp}"
    temp_dir = f"temp_{package_name}"
    # æœ€æ–°ã®HTMLãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æ—¥æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å–å¾—
    html_dir = Path(latest_html).parent.parent
    output_dir = f"{html_dir}/packages"
    Path(output_dir).mkdir(parents=True, exist_ok=True)
    
    zip_file = f"{output_dir}/{package_name}.zip"
    
    try:
        # ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        if os.path.exists(temp_dir):
            shutil.rmtree(temp_dir)
        os.makedirs(temp_dir)
        
        # ãƒ¡ã‚¤ãƒ³HTMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’index.htmlã¨ã—ã¦ã‚³ãƒ”ãƒ¼
        shutil.copy2(latest_html, os.path.join(temp_dir, "index.html"))
        print(f"âœ… ãƒ¡ã‚¤ãƒ³HTML: index.html")
        
        # åˆ†æç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’åé›†
        images_dir = os.path.join(temp_dir, "images")
        os.makedirs(images_dir)
        
        # professional_analysis_*.png ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åé›†
        analysis_images = glob.glob("reports/*/images/professional_analysis_*.png")
        print(f"ğŸ“¸ åˆ†æç”»åƒ: {len(analysis_images)}æš")
        
        for img in analysis_images:
            shutil.copy2(img, images_dir)
        
        # å…ƒç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’åé›†
        original_images = glob.glob("graphs/original/*.jpg")
        print(f"ğŸ“· å…ƒç”»åƒ: {len(original_images)}æš")
        
        for img in original_images:
            shutil.copy2(img, images_dir)
        
        # HTMLãƒ•ã‚¡ã‚¤ãƒ«å†…ã®ãƒ‘ã‚¹ã‚’èª¿æ•´
        adjust_html_paths(os.path.join(temp_dir, "index.html"))
        
        # README.txtã‚’ä½œæˆ
        create_readme(temp_dir, package_name)
        
        # package.jsonã‚’ä½œæˆï¼ˆWebç”¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ï¼‰
        create_package_json(temp_dir, package_name)
        
        # .htaccessã‚’ä½œæˆï¼ˆWebé…ä¿¡ç”¨è¨­å®šï¼‰
        create_htaccess(temp_dir)
        
        # ZIPãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
        print("ğŸ—œï¸ ZIPãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆä¸­...")
        
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        Path("reports/packages").mkdir(parents=True, exist_ok=True)
        
        with zipfile.ZipFile(zip_file, 'w', zipfile.ZIP_DEFLATED) as zipf:
            for root, dirs, files in os.walk(temp_dir):
                for file in files:
                    file_path = os.path.join(root, file)
                    arc_path = os.path.relpath(file_path, temp_dir)
                    zipf.write(file_path, arc_path)
        
        # ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å‰Šé™¤
        shutil.rmtree(temp_dir)
        
        # ZIPãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±è¡¨ç¤º
        zip_size = os.path.getsize(zip_file)
        print("=" * 60)
        print("âœ… Webé…ä¿¡ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ä½œæˆå®Œäº†")
        print(f"ğŸ“¦ ãƒ•ã‚¡ã‚¤ãƒ«å: {zip_file}")
        print(f"ğŸ“Š ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {zip_size / 1024 / 1024:.2f} MB")
        
        # ZIPãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’è¡¨ç¤º
        print("\nğŸ“‹ ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸å†…å®¹:")
        with zipfile.ZipFile(zip_file, 'r') as zipf:
            for info in zipf.infolist():
                size_kb = info.file_size / 1024
                print(f"   {info.filename} ({size_kb:.1f} KB)")
        
        return zip_file
        
    except Exception as e:
        print(f"âŒ ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
        if os.path.exists(temp_dir):
            shutil.rmtree(temp_dir)
        return None

def adjust_html_paths(html_file):
    """HTMLãƒ•ã‚¡ã‚¤ãƒ«å†…ã®ç”»åƒãƒ‘ã‚¹ã‚’èª¿æ•´"""
    with open(html_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # reports/YYYYMMDD/images/professional_analysis_*.png ã®ãƒ‘ã‚¹ã‚’èª¿æ•´
    import re
    content = re.sub(r'reports/\d{8}/images/professional_analysis_([^"]+\.png)', r'images/professional_analysis_\1', content)
    # æ—§ãƒ‘ã‚¹ã®èª¿æ•´ï¼ˆäº’æ›æ€§ã®ãŸã‚ï¼‰
    content = re.sub(r'(?<!/)professional_analysis_([^"]+\.png)', r'images/professional_analysis_\1', content)
    
    # graphs/original/*.jpg ã®ãƒ‘ã‚¹ã‚’èª¿æ•´  
    content = re.sub(r'graphs/original/([^"]+\.jpg)', r'images/\1', content)
    
    with open(html_file, 'w', encoding='utf-8') as f:
        f.write(content)
    
    print("âœ… HTMLãƒ‘ã‚¹èª¿æ•´å®Œäº†")

def create_readme(temp_dir, package_name):
    """README.txtã‚’ä½œæˆ"""
    readme_content = f"""
ğŸ“Š PPã‚¿ã‚¦ãƒ³æ§˜ ãƒ‘ãƒãƒ³ã‚³ã‚°ãƒ©ãƒ•åˆ†æãƒ¬ãƒãƒ¼ãƒˆ
==================================================

ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸å: {package_name}
ä½œæˆæ—¥æ™‚: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}

ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«æ§‹æˆ:
â”œâ”€â”€ index.html          ... ãƒ¡ã‚¤ãƒ³ãƒ¬ãƒãƒ¼ãƒˆï¼ˆãƒ–ãƒ©ã‚¦ã‚¶ã§é–‹ã„ã¦ãã ã•ã„ï¼‰
â”œâ”€â”€ images/             ... ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«
â”‚   â”œâ”€â”€ *.png          ... AIåˆ†æçµæœç”»åƒ
â”‚   â””â”€â”€ *.jpg          ... å…ƒç”»åƒãƒ•ã‚¡ã‚¤ãƒ«
â”œâ”€â”€ README.txt          ... ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«
â”œâ”€â”€ package.json        ... Webãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
â””â”€â”€ .htaccess          ... Webé…ä¿¡è¨­å®š

ğŸŒ Webé…ä¿¡æ–¹æ³•:
1. ã“ã®ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’Webã‚µãƒ¼ãƒãƒ¼ã«å±•é–‹
2. ãƒ–ãƒ©ã‚¦ã‚¶ã§index.htmlã«ã‚¢ã‚¯ã‚»ã‚¹
3. ãƒ¢ãƒã‚¤ãƒ«ãƒ»ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—å¯¾å¿œ

ğŸ”§ æŠ€è¡“ä»•æ§˜:
- HTML5 + CSS3 + JavaScript
- ãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–ãƒ‡ã‚¶ã‚¤ãƒ³
- é«˜è§£åƒåº¦ç”»åƒå¯¾å¿œ
- æœ€æ–°ãƒ–ãƒ©ã‚¦ã‚¶æ¨å¥¨

ğŸ¨ åˆ¶ä½œ:
Report Design: ãƒ•ã‚¡ã‚¤ãƒ–ãƒŠã‚¤ãƒ³ãƒ‡ã‚¶ã‚¤ãƒ³ - ä½è—¤
AI Analysis: Next-Gen ML Platform

Â© 2024 PPã‚¿ã‚¦ãƒ³æ§˜å°‚ç”¨ãƒ¬ãƒãƒ¼ãƒˆ | æ©Ÿå¯†æƒ…å ±å–æ‰±æ³¨æ„
"""
    
    with open(os.path.join(temp_dir, "README.txt"), 'w', encoding='utf-8') as f:
        f.write(readme_content)
    
    print("âœ… README.txtä½œæˆå®Œäº†")

def create_package_json(temp_dir, package_name):
    """package.jsonã‚’ä½œæˆï¼ˆWebç”¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ï¼‰"""
    package_data = {
        "name": package_name,
        "version": "1.0.0",
        "description": "PPã‚¿ã‚¦ãƒ³æ§˜ ãƒ‘ãƒãƒ³ã‚³ã‚°ãƒ©ãƒ•åˆ†æãƒ¬ãƒãƒ¼ãƒˆ - AIé«˜ç²¾åº¦è§£æã‚·ã‚¹ãƒ†ãƒ ",
        "main": "index.html",
        "keywords": ["pachinko", "graph", "analysis", "ai", "report"],
        "author": "ãƒ•ã‚¡ã‚¤ãƒ–ãƒŠã‚¤ãƒ³ãƒ‡ã‚¶ã‚¤ãƒ³ - ä½è—¤",
        "license": "Proprietary",
        "private": True,
        "created": datetime.now().isoformat(),
        "client": "PPã‚¿ã‚¦ãƒ³æ§˜",
        "type": "analysis-report",
        "technologies": [
            "HTML5",
            "CSS3", 
            "JavaScript",
            "AI Machine Learning",
            "Computer Vision",
            "OCR"
        ],
        "features": [
            "10è‰²ã‚°ãƒ©ãƒ•ç·šæ¤œå‡º",
            "Â±1pxç²¾åº¦æ¸¬å®š", 
            "è‡ªå‹•0ãƒ©ã‚¤ãƒ³æ¤œå‡º",
            "ãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–ãƒ‡ã‚¶ã‚¤ãƒ³",
            "é«˜è§£åƒåº¦ç”»åƒå¯¾å¿œ"
        ]
    }
    
    with open(os.path.join(temp_dir, "package.json"), 'w', encoding='utf-8') as f:
        json.dump(package_data, f, ensure_ascii=False, indent=2)
    
    print("âœ… package.jsonä½œæˆå®Œäº†")

def create_htaccess(temp_dir):
    """Webé…ä¿¡ç”¨.htaccessã‚’ä½œæˆ"""
    htaccess_content = """
# PPã‚¿ã‚¦ãƒ³æ§˜ ãƒ‘ãƒãƒ³ã‚³ã‚°ãƒ©ãƒ•åˆ†æãƒ¬ãƒãƒ¼ãƒˆ - Webé…ä¿¡è¨­å®š

# MIME Types
AddType text/html .html
AddType application/json .json
AddType image/png .png
AddType image/jpeg .jpg

# ã‚­ãƒ£ãƒƒã‚·ãƒ¥è¨­å®š
<IfModule mod_expires.c>
    ExpiresActive On
    ExpiresByType text/html "access plus 1 hour"
    ExpiresByType image/png "access plus 1 week"
    ExpiresByType image/jpeg "access plus 1 week"
    ExpiresByType application/json "access plus 1 day"
</IfModule>

# åœ§ç¸®è¨­å®š
<IfModule mod_deflate.c>
    AddOutputFilterByType DEFLATE text/html
    AddOutputFilterByType DEFLATE text/css
    AddOutputFilterByType DEFLATE application/javascript
    AddOutputFilterByType DEFLATE application/json
</IfModule>

# ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ˜ãƒƒãƒ€ãƒ¼
<IfModule mod_headers.c>
    Header always set X-Content-Type-Options nosniff
    Header always set X-Frame-Options DENY
    Header always set X-XSS-Protection "1; mode=block"
</IfModule>

# DirectoryIndex
DirectoryIndex index.html

# ã‚¨ãƒ©ãƒ¼ãƒšãƒ¼ã‚¸
ErrorDocument 404 /index.html
"""
    
    with open(os.path.join(temp_dir, ".htaccess"), 'w', encoding='utf-8') as f:
        f.write(htaccess_content)
    
    print("âœ… .htaccessä½œæˆå®Œäº†")

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    print("ğŸŒ Webé…ä¿¡ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ä½œæˆãƒ„ãƒ¼ãƒ«")
    print("ğŸ“Š PPã‚¿ã‚¦ãƒ³æ§˜å°‚ç”¨ãƒ¬ãƒãƒ¼ãƒˆ")
    print("=" * 60)
    
    zip_file = create_web_package()
    
    if zip_file:
        print("\nğŸ‰ ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ä½œæˆæˆåŠŸï¼")
        print(f"ğŸ“¦ é…ä¿¡ç”¨ãƒ•ã‚¡ã‚¤ãƒ«: {zip_file}")
        print("\nğŸ’¡ ä½¿ç”¨æ–¹æ³•:")
        print("1. ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’Webã‚µãƒ¼ãƒãƒ¼ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
        print("2. ã‚µãƒ¼ãƒãƒ¼ä¸Šã§å±•é–‹")
        print("3. index.htmlã«ãƒ–ãƒ©ã‚¦ã‚¶ã§ã‚¢ã‚¯ã‚»ã‚¹")
        print("\nğŸ”’ æ©Ÿå¯†æƒ…å ±å–æ‰±æ³¨æ„")
    else:
        print("âŒ ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸ")

if __name__ == "__main__":
    main()