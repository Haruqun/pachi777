#!/usr/bin/env python3
"""
é«˜ç²¾åº¦ãƒ‘ãƒãƒ³ã‚³ã‚°ãƒ©ãƒ•åˆ‡ã‚ŠæŠœããƒ„ãƒ¼ãƒ«
- è¤‡æ•°ã®æ¤œå‡ºæ‰‹æ³•ã‚’çµ„ã¿åˆã‚ã›
- AIå­¦ç¿’ã«ã‚ˆã‚‹ç²¾åº¦å‘ä¸Š
- è©³ç´°ãªæ¤œè¨¼ãƒ»è©•ä¾¡æ©Ÿèƒ½
- å®Œç’§ãªç²¾åº¦ã‚’ç›®æŒ‡ã—ãŸæœ€æ–°ç‰ˆ
"""

import os
import json
import numpy as np
from PIL import Image, ImageDraw, ImageFont
import pandas as pd
from datetime import datetime
from typing import Tuple, List, Optional, Dict, Any
from scipy import ndimage
from scipy.signal import find_peaks
import cv2

# ã‚ªãƒ—ã‚·ãƒ§ãƒŠãƒ«æ©Ÿèƒ½
try:
    import matplotlib.pyplot as plt
    import matplotlib.patches as patches
    PLOT_AVAILABLE = True
except ImportError:
    PLOT_AVAILABLE = False

try:
    from sklearn.cluster import KMeans, DBSCAN
    from sklearn.preprocessing import StandardScaler
    ML_AVAILABLE = True
except ImportError:
    ML_AVAILABLE = False


class HighPrecisionCropper:
    """é«˜ç²¾åº¦ã‚°ãƒ©ãƒ•åˆ‡ã‚ŠæŠœãã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        self.debug_mode = True
        self.detection_results = []
        self.ground_truth_data = []
        self.learning_data = {}
        
    def log(self, message, level="INFO"):
        """ãƒ­ã‚°å‡ºåŠ›"""
        if self.debug_mode:
            timestamp = datetime.now().strftime("%H:%M:%S")
            symbols = {"INFO": "ğŸ“‹", "SUCCESS": "âœ…", "WARNING": "âš ï¸", "ERROR": "âŒ", "DEBUG": "ğŸ”"}
            print(f"{symbols.get(level, 'ğŸ“‹')} [{timestamp}] {message}")
    
    # =====================================
    # 1. åŸºæœ¬æ¤œå‡ºæ‰‹æ³•
    # =====================================
    
    def hex_to_rgb(self, hex_color: str) -> Tuple[int, int, int]:
        """16é€²æ•°ã‚«ãƒ©ãƒ¼ã‚³ãƒ¼ãƒ‰ã‚’RGBã«å¤‰æ›"""
        hex_color = hex_color.lstrip('#')
        return tuple(int(hex_color[i:i+2], 16) for i in (0, 2, 4))
    
    def detect_by_color_analysis(self, image_path: str, target_colors: List[str] = None) -> Optional[Tuple[int, int, int, int]]:
        """è‰²åˆ†æã«ã‚ˆã‚‹æ¤œå‡ºï¼ˆæ”¹è‰¯ç‰ˆï¼‰"""
        self.log("è‰²åˆ†ææ¤œå‡ºã‚’é–‹å§‹", "DEBUG")
        
        if target_colors is None:
            target_colors = ["#f5ece7", "#f0e6e1", "#e8ddd7", "#ede3dd"]
        
        img = Image.open(image_path)
        img_array = np.array(img)
        height, width = img_array.shape[:2]
        
        # è¤‡æ•°è‰²ã§ã®çµ±åˆæ¤œå‡º
        combined_mask = np.zeros((height, width), dtype=bool)
        
        for color in target_colors:
            target_rgb = np.array(self.hex_to_rgb(color))
            
            # è‰²è·é›¢è¨ˆç®—ï¼ˆæ”¹è‰¯ç‰ˆï¼‰
            reshaped = img_array[:, :, :3].reshape(-1, 3).astype(np.float64)
            distances = np.sqrt(np.sum((reshaped - target_rgb) ** 2, axis=1))
            
            # å‹•çš„é–¾å€¤è¨ˆç®—
            threshold = np.percentile(distances, 15)  # ä¸‹ä½15%
            threshold = max(10, min(threshold, 30))  # ç¯„å›²åˆ¶é™
            
            mask = distances <= threshold
            mask_2d = mask.reshape(height, width)
            combined_mask = combined_mask | mask_2d
        
        return self._extract_bounds_from_mask(combined_mask, width, height, "è‰²åˆ†æ")
    
    def detect_by_texture_analysis(self, image_path: str) -> Optional[Tuple[int, int, int, int]]:
        """ãƒ†ã‚¯ã‚¹ãƒãƒ£åˆ†æã«ã‚ˆã‚‹æ¤œå‡º"""
        self.log("ãƒ†ã‚¯ã‚¹ãƒãƒ£åˆ†ææ¤œå‡ºã‚’é–‹å§‹", "DEBUG")
        
        img = Image.open(image_path)
        img_array = np.array(img)
        gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)
        height, width = gray.shape
        
        # ã‚¬ãƒœãƒ¼ãƒ«ãƒ•ã‚£ãƒ«ã‚¿ã«ã‚ˆã‚‹ãƒ†ã‚¯ã‚¹ãƒãƒ£è§£æ
        kernels = []
        for theta in range(0, 180, 30):
            kernel = cv2.getGaborKernel((21, 21), 5, np.radians(theta), 2*np.pi*0.5, 0.5, 0, ktype=cv2.CV_32F)
            kernels.append(kernel)
        
        # ãƒ†ã‚¯ã‚¹ãƒãƒ£ç‰¹å¾´ã‚’æŠ½å‡º
        texture_responses = []
        for kernel in kernels:
            filtered = cv2.filter2D(gray, cv2.CV_8UC3, kernel)
            texture_responses.append(filtered)
        
        # çµ±åˆãƒ†ã‚¯ã‚¹ãƒãƒ£ãƒãƒƒãƒ—
        texture_map = np.mean(texture_responses, axis=0)
        
        # ã‚°ãƒ©ãƒ•ã‚¨ãƒªã‚¢ç‰¹æœ‰ã®ãƒ†ã‚¯ã‚¹ãƒãƒ£ã‚’æ¤œå‡º
        # ã‚°ãƒ©ãƒ•ã‚¨ãƒªã‚¢ã¯æ¯”è¼ƒçš„å‡ä¸€ãªãƒ†ã‚¯ã‚¹ãƒãƒ£ã‚’æŒã¤
        texture_variance = ndimage.generic_filter(texture_map, np.var, size=20)
        
        # ä½åˆ†æ•£ã‚¨ãƒªã‚¢ï¼ˆå‡ä¸€ãªã‚¨ãƒªã‚¢ï¼‰ã‚’æ¤œå‡º
        uniform_mask = texture_variance < np.percentile(texture_variance, 25)
        
        return self._extract_bounds_from_mask(uniform_mask, width, height, "ãƒ†ã‚¯ã‚¹ãƒãƒ£åˆ†æ")
    
    def detect_by_edge_analysis(self, image_path: str) -> Optional[Tuple[int, int, int, int]]:
        """ã‚¨ãƒƒã‚¸åˆ†æã«ã‚ˆã‚‹æ¤œå‡ºï¼ˆé«˜ç²¾åº¦ç‰ˆï¼‰"""
        self.log("ã‚¨ãƒƒã‚¸åˆ†ææ¤œå‡ºã‚’é–‹å§‹", "DEBUG")
        
        img = Image.open(image_path)
        img_array = np.array(img)
        gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)
        height, width = gray.shape
        
        # ãƒãƒ«ãƒã‚¹ã‚±ãƒ¼ãƒ«ã‚¨ãƒƒã‚¸æ¤œå‡º
        edges_multi = np.zeros_like(gray, dtype=np.float32)
        
        # è¤‡æ•°ã®é–¾å€¤ã§Cannyã‚¨ãƒƒã‚¸æ¤œå‡º
        thresholds = [(30, 100), (50, 150), (70, 200)]
        for low, high in thresholds:
            edges = cv2.Canny(gray, low, high)
            edges_multi += edges.astype(np.float32)
        
        # ã‚¨ãƒƒã‚¸å¯†åº¦ãƒãƒƒãƒ—
        edge_density = ndimage.uniform_filter(edges_multi, size=20)
        
        # ã‚°ãƒ©ãƒ•å¢ƒç•Œã®ç‰¹å¾´ï¼šä¸­ç¨‹åº¦ã®ã‚¨ãƒƒã‚¸å¯†åº¦
        graph_mask = (edge_density > np.percentile(edge_density, 30)) & \
                     (edge_density < np.percentile(edge_density, 85))
        
        return self._extract_bounds_from_mask(graph_mask, width, height, "ã‚¨ãƒƒã‚¸åˆ†æ")
    
    def detect_by_gradient_analysis(self, image_path: str) -> Optional[Tuple[int, int, int, int]]:
        """ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³åˆ†æã«ã‚ˆã‚‹æ¤œå‡º"""
        self.log("ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³åˆ†ææ¤œå‡ºã‚’é–‹å§‹", "DEBUG")
        
        img = Image.open(image_path)
        img_array = np.array(img)
        height, width = img_array.shape[:2]
        
        # å„ãƒãƒ£ãƒ³ãƒãƒ«ã§ã®ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³è¨ˆç®—
        gradients = []
        for channel in range(3):
            grad_x = np.gradient(img_array[:, :, channel], axis=1)
            grad_y = np.gradient(img_array[:, :, channel], axis=0)
            grad_magnitude = np.sqrt(grad_x**2 + grad_y**2)
            gradients.append(grad_magnitude)
        
        # çµ±åˆã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
        combined_gradient = np.mean(gradients, axis=0)
        
        # ã‚°ãƒ©ãƒ•ã‚¨ãƒªã‚¢ã¯æ¯”è¼ƒçš„ä½ã„ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
        low_gradient_mask = combined_gradient < np.percentile(combined_gradient, 40)
        
        return self._extract_bounds_from_mask(low_gradient_mask, width, height, "ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³åˆ†æ")
    
    def detect_by_layout_analysis(self, image_path: str) -> Optional[Tuple[int, int, int, int]]:
        """ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆåˆ†æã«ã‚ˆã‚‹æ¤œå‡ºï¼ˆãƒ‘ãƒãƒ³ã‚³ã‚¢ãƒ—ãƒªç‰¹åŒ–ï¼‰"""
        self.log("ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆåˆ†ææ¤œå‡ºã‚’é–‹å§‹", "DEBUG")
        
        img = Image.open(image_path)
        width, height = img.size
        
        # ãƒ‘ãƒãƒ³ã‚³ã‚¢ãƒ—ãƒªã®ç”»é¢è§£åƒåº¦åˆ¥ã®æœ€é©åŒ–
        resolution_configs = {
            # é«˜è§£åƒåº¦ï¼ˆiPhone Proç³»ï¼‰
            "high": {"min_height": 2400, "top": 0.32, "bottom": 0.38, "left": 0.05, "right": 0.02},
            # æ¨™æº–è§£åƒåº¦
            "standard": {"min_height": 1800, "top": 0.30, "bottom": 0.35, "left": 0.06, "right": 0.03},
            # ä½è§£åƒåº¦
            "low": {"min_height": 0, "top": 0.28, "bottom": 0.40, "left": 0.08, "right": 0.04}
        }
        
        # è§£åƒåº¦ã«å¿œã˜ãŸè¨­å®šé¸æŠ
        config = None
        for res_type, res_config in resolution_configs.items():
            if height >= res_config["min_height"]:
                config = res_config
                break
        
        if config is None:
            config = resolution_configs["low"]
        
        # åº§æ¨™è¨ˆç®—
        left = int(width * config["left"])
        right = int(width * (1 - config["right"]))
        top = int(height * config["top"])
        bottom = int(height * (1 - config["bottom"]))
        
        self.log(f"ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆæ¤œå‡º: {left}, {top}, {right}, {bottom} (è§£åƒåº¦: {width}x{height})", "DEBUG")
        
        return (left, top, right, bottom)
    
    def detect_by_orange_bar(self, image_path: str) -> Optional[Tuple[int, int, int, int]]:
        """ã‚ªãƒ¬ãƒ³ã‚¸ãƒãƒ¼æ¤œå‡ºã«ã‚ˆã‚‹é«˜ç²¾åº¦ä½ç½®ç‰¹å®š"""
        self.log("ã‚ªãƒ¬ãƒ³ã‚¸ãƒãƒ¼æ¤œå‡ºã‚’é–‹å§‹", "DEBUG")
        
        img = Image.open(image_path)
        img_array = np.array(img)
        height, width = img_array.shape[:2]
        
        # HSVè‰²ç©ºé–“ã§ã®æ¤œå‡ºï¼ˆã‚ˆã‚Šç²¾å¯†ï¼‰
        hsv = cv2.cvtColor(img_array, cv2.COLOR_RGB2HSV)
        
        # ã‚ªãƒ¬ãƒ³ã‚¸è‰²ã®ç¯„å›²ï¼ˆHSVï¼‰
        orange_ranges = [
            # æ˜ã‚‹ã„ã‚ªãƒ¬ãƒ³ã‚¸
            ([15, 100, 100], [25, 255, 255]),
            # æ¿ƒã„ã‚ªãƒ¬ãƒ³ã‚¸
            ([10, 150, 150], [20, 255, 255]),
            # èµ¤ã¿ãŒã‹ã£ãŸã‚ªãƒ¬ãƒ³ã‚¸
            ([5, 120, 120], [15, 255, 255])
        ]
        
        orange_mask = np.zeros((height, width), dtype=np.uint8)
        
        for lower, upper in orange_ranges:
            lower = np.array(lower)
            upper = np.array(upper)
            mask = cv2.inRange(hsv, lower, upper)
            orange_mask = cv2.bitwise_or(orange_mask, mask)
        
        # æ°´å¹³ç·šæ¤œå‡º
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (width//4, 1))
        orange_lines = cv2.morphologyEx(orange_mask, cv2.MORPH_OPEN, kernel)
        
        # ã‚ªãƒ¬ãƒ³ã‚¸ãƒãƒ¼ã®ä½ç½®ã‚’ç‰¹å®š
        line_positions = []
        for y in range(height):
            if np.sum(orange_lines[y, :]) > width * 0.3:  # è¡Œã®30%ä»¥ä¸ŠãŒã‚ªãƒ¬ãƒ³ã‚¸
                line_positions.append(y)
        
        if not line_positions:
            self.log("ã‚ªãƒ¬ãƒ³ã‚¸ãƒãƒ¼ãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ", "WARNING")
            return None
        
        # æœ€ã‚‚å¤ªã„ã‚ªãƒ¬ãƒ³ã‚¸ãƒãƒ¼ã‚’é¸æŠ
        orange_top = min(line_positions)
        orange_bottom = max(line_positions)
        
        # ã‚°ãƒ©ãƒ•ã‚¨ãƒªã‚¢ã¯ã‚ªãƒ¬ãƒ³ã‚¸ãƒãƒ¼ã®ç›´ä¸‹
        graph_top = orange_bottom + 5
        graph_bottom = min(height - 50, graph_top + int(height * 0.25))
        graph_left = int(width * 0.04)
        graph_right = int(width * 0.96)
        
        self.log(f"ã‚ªãƒ¬ãƒ³ã‚¸ãƒãƒ¼åŸºæº–æ¤œå‡º: {graph_left}, {graph_top}, {graph_right}, {graph_bottom}", "DEBUG")
        
        return (graph_left, graph_top, graph_right, graph_bottom)
    
    # =====================================
    # 2. AIãƒ»æ©Ÿæ¢°å­¦ç¿’ã«ã‚ˆã‚‹æ¤œå‡º
    # =====================================
    
    def detect_by_clustering(self, image_path: str) -> Optional[Tuple[int, int, int, int]]:
        """ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã«ã‚ˆã‚‹é ˜åŸŸåˆ†å‰²"""
        if not ML_AVAILABLE:
            self.log("scikit-learnãŒåˆ©ç”¨ã§ãã¾ã›ã‚“", "WARNING")
            return None
        
        self.log("ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°æ¤œå‡ºã‚’é–‹å§‹", "DEBUG")
        
        img = Image.open(image_path)
        img_array = np.array(img)
        height, width = img_array.shape[:2]
        
        # ç‰¹å¾´é‡æŠ½å‡º
        features = []
        
        # 1. è‰²ç‰¹å¾´
        reshaped_img = img_array.reshape(-1, 3)
        
        # 2. ä½ç½®ç‰¹å¾´
        y_coords, x_coords = np.mgrid[0:height, 0:width]
        positions = np.column_stack([y_coords.ravel(), x_coords.ravel()])
        
        # 3. ãƒ†ã‚¯ã‚¹ãƒãƒ£ç‰¹å¾´ï¼ˆç°¡æ˜“ç‰ˆï¼‰
        gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)
        
        # ãƒ­ãƒ¼ã‚«ãƒ«æ¨™æº–åå·®
        local_std = ndimage.generic_filter(gray, np.std, size=5).ravel()
        
        # ç‰¹å¾´é‡çµåˆ
        features = np.column_stack([
            reshaped_img,           # RGBå€¤
            positions / [height, width],  # æ­£è¦åŒ–ä½ç½®
            local_std.reshape(-1, 1)  # ãƒ†ã‚¯ã‚¹ãƒãƒ£
        ])
        
        # ç‰¹å¾´é‡æ­£è¦åŒ–
        scaler = StandardScaler()
        features_scaled = scaler.fit_transform(features)
        
        # K-meansã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°
        n_clusters = 8
        kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
        cluster_labels = kmeans.fit_predict(features_scaled)
        
        # ã‚¯ãƒ©ã‚¹ã‚¿ãƒãƒƒãƒ—ã‚’ç”»åƒå½¢çŠ¶ã«æˆ»ã™
        cluster_map = cluster_labels.reshape(height, width)
        
        # ã‚°ãƒ©ãƒ•ã‚¨ãƒªã‚¢ã«å¯¾å¿œã™ã‚‹ã‚¯ãƒ©ã‚¹ã‚¿ã‚’ç‰¹å®š
        # ä¸­å¤®éƒ¨åˆ†ã®æœ€ã‚‚å¤šã„ã‚¯ãƒ©ã‚¹ã‚¿ã‚’é¸æŠ
        center_region = cluster_map[height//3:2*height//3, width//4:3*width//4]
        center_clusters, counts = np.unique(center_region, return_counts=True)
        main_cluster = center_clusters[np.argmax(counts)]
        
        # ãƒ¡ã‚¤ãƒ³ã‚¯ãƒ©ã‚¹ã‚¿ã‚’ãƒã‚¹ã‚¯ã¨ã—ã¦ä½¿ç”¨
        cluster_mask = cluster_map == main_cluster
        
        return self._extract_bounds_from_mask(cluster_mask, width, height, "ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°")
    
    def detect_by_pattern_matching(self, image_path: str) -> Optional[Tuple[int, int, int, int]]:
        """ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°ã«ã‚ˆã‚‹æ¤œå‡º"""
        self.log("ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°æ¤œå‡ºã‚’é–‹å§‹", "DEBUG")
        
        img = Image.open(image_path)
        img_array = np.array(img)
        gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)
        height, width = gray.shape
        
        # ã‚°ãƒ©ãƒ•ã‚¨ãƒªã‚¢ã®å…¸å‹çš„ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å®šç¾©
        patterns = []
        
        # 1. æ°´å¹³ã‚°ãƒªãƒƒãƒ‰ãƒ©ã‚¤ãƒ³æ¤œå‡º
        horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (width//8, 1))
        horizontal_lines = cv2.morphologyEx(gray, cv2.MORPH_OPEN, horizontal_kernel)
        
        # 2. å‚ç›´ã‚°ãƒªãƒƒãƒ‰ãƒ©ã‚¤ãƒ³æ¤œå‡º
        vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, height//8))
        vertical_lines = cv2.morphologyEx(gray, cv2.MORPH_OPEN, vertical_kernel)
        
        # 3. ã‚°ãƒªãƒƒãƒ‰ãƒ‘ã‚¿ãƒ¼ãƒ³ã®çµ±åˆ
        grid_pattern = cv2.add(horizontal_lines, vertical_lines)
        
        # ã‚°ãƒªãƒƒãƒ‰ãŒé›†ä¸­ã—ã¦ã„ã‚‹é ˜åŸŸã‚’æ¤œå‡º
        grid_density = ndimage.uniform_filter(grid_pattern.astype(float), size=30)
        
        # é–¾å€¤å‡¦ç†
        threshold = np.percentile(grid_density, 75)
        grid_mask = grid_density > threshold
        
        return self._extract_bounds_from_mask(grid_mask, width, height, "ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°")
    
    # =====================================
    # 3. çµ±åˆæ¤œå‡ºã‚·ã‚¹ãƒ†ãƒ 
    # =====================================
    
    def ensemble_detection(self, image_path: str) -> Tuple[int, int, int, int]:
        """è¤‡æ•°æ‰‹æ³•ã‚’çµ±åˆã—ãŸé«˜ç²¾åº¦æ¤œå‡º"""
        self.log(f"çµ±åˆæ¤œå‡ºã‚’é–‹å§‹: {os.path.basename(image_path)}", "INFO")
        
        # å…¨æ¤œå‡ºæ‰‹æ³•ã‚’å®Ÿè¡Œ
        detection_methods = [
            ("è‰²åˆ†æ", self.detect_by_color_analysis),
            ("ãƒ†ã‚¯ã‚¹ãƒãƒ£åˆ†æ", self.detect_by_texture_analysis),
            ("ã‚¨ãƒƒã‚¸åˆ†æ", self.detect_by_edge_analysis),
            ("ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³åˆ†æ", self.detect_by_gradient_analysis),
            ("ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆåˆ†æ", self.detect_by_layout_analysis),
            ("ã‚ªãƒ¬ãƒ³ã‚¸ãƒãƒ¼æ¤œå‡º", self.detect_by_orange_bar),
            ("ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°", self.detect_by_clustering),
            ("ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°", self.detect_by_pattern_matching)
        ]
        
        results = []
        
        for method_name, method_func in detection_methods:
            try:
                bounds = method_func(image_path)
                if bounds:
                    left, top, right, bottom = bounds
                    area = (right - left) * (bottom - top)
                    
                    # çµæœã®å¦¥å½“æ€§æ¤œè¨¼
                    quality_score = self._evaluate_bounds_quality(bounds, image_path)
                    
                    results.append({
                        'method': method_name,
                        'bounds': bounds,
                        'area': area,
                        'quality_score': quality_score
                    })
                    
                    self.log(f"{method_name}: {bounds} (å“è³ª: {quality_score:.2f})", "DEBUG")
                else:
                    self.log(f"{method_name}: æ¤œå‡ºå¤±æ•—", "WARNING")
            except Exception as e:
                self.log(f"{method_name}: ã‚¨ãƒ©ãƒ¼ - {e}", "ERROR")
        
        if not results:
            self.log("å…¨ã¦ã®æ‰‹æ³•ã§æ¤œå‡ºã«å¤±æ•—ã—ã¾ã—ãŸ", "ERROR")
            return self._fallback_detection(image_path)
        
        # çµ±åˆã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 
        final_bounds = self._combine_detection_results(results, image_path)
        
        self.log(f"æœ€çµ‚æ¤œå‡ºçµæœ: {final_bounds}", "SUCCESS")
        
        # çµæœã‚’ä¿å­˜ï¼ˆå­¦ç¿’ç”¨ï¼‰
        self.detection_results.append({
            'image_path': image_path,
            'methods_results': results,
            'final_bounds': final_bounds,
            'timestamp': datetime.now().isoformat()
        })
        
        return final_bounds
    
    def _extract_bounds_from_mask(self, mask: np.ndarray, width: int, height: int, method_name: str) -> Optional[Tuple[int, int, int, int]]:
        """ãƒã‚¹ã‚¯ã‹ã‚‰å¢ƒç•Œã‚’æŠ½å‡º"""
        if np.sum(mask) < 100:  # ãƒã‚¹ã‚¯ãŒå°ã•ã™ãã‚‹
            return None
        
        # é€£çµæˆåˆ†åˆ†æ
        labeled_mask, num_features = ndimage.label(mask)
        
        if num_features == 0:
            return None
        
        # æœ€å¤§ã®é€£çµæˆåˆ†ã‚’é¸æŠ
        component_sizes = ndimage.sum(mask, labeled_mask, range(1, num_features + 1))
        largest_component = np.argmax(component_sizes) + 1
        largest_mask = labeled_mask == largest_component
        
        # å¢ƒç•ŒæŠ½å‡º
        rows, cols = np.where(largest_mask)
        
        if len(rows) == 0:
            return None
        
        top, bottom = rows.min(), rows.max()
        left, right = cols.min(), cols.max()
        
        # ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°
        padding = 10
        left = max(0, left - padding)
        right = min(width - 1, right + padding)
        top = max(0, top - padding)
        bottom = min(height - 1, bottom + padding)
        
        return (left, top, right, bottom)
    
    def _evaluate_bounds_quality(self, bounds: Tuple[int, int, int, int], image_path: str) -> float:
        """æ¤œå‡ºçµæœã®å“è³ªè©•ä¾¡"""
        left, top, right, bottom = bounds
        
        img = Image.open(image_path)
        width, height = img.size
        
        # åŸºæœ¬çš„ãªå¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯
        area_ratio = ((right - left) * (bottom - top)) / (width * height)
        width_ratio = (right - left) / width
        height_ratio = (bottom - top) / height
        
        quality_score = 0
        
        # é¢ç©æ¯”ç‡è©•ä¾¡ï¼ˆ15-40%ãŒç†æƒ³ï¼‰
        if 0.15 <= area_ratio <= 0.40:
            quality_score += 30
        elif 0.10 <= area_ratio <= 0.50:
            quality_score += 20
        elif 0.05 <= area_ratio <= 0.60:
            quality_score += 10
        
        # æ¨ªå¹…æ¯”ç‡è©•ä¾¡ï¼ˆ85-98%ãŒç†æƒ³ï¼‰
        if 0.85 <= width_ratio <= 0.98:
            quality_score += 30
        elif 0.70 <= width_ratio <= 0.99:
            quality_score += 20
        elif 0.50 <= width_ratio <= 1.0:
            quality_score += 10
        
        # é«˜ã•æ¯”ç‡è©•ä¾¡ï¼ˆ20-35%ãŒç†æƒ³ï¼‰
        if 0.20 <= height_ratio <= 0.35:
            quality_score += 25
        elif 0.15 <= height_ratio <= 0.45:
            quality_score += 15
        elif 0.10 <= height_ratio <= 0.55:
            quality_score += 5
        
        # ä½ç½®è©•ä¾¡ï¼ˆä¸­å¤®å¯„ã‚ŠãŒç†æƒ³ï¼‰
        center_x = (left + right) / 2
        center_y = (top + bottom) / 2
        
        x_center_score = 1 - abs(center_x / width - 0.5) * 2
        y_center_score = 1 - abs(center_y / height - 0.4) * 2  # å°‘ã—ä¸Šå¯„ã‚Š
        
        quality_score += x_center_score * 10
        quality_score += y_center_score * 5
        
        return min(quality_score, 100)
    
    def _combine_detection_results(self, results: List[Dict], image_path: str) -> Tuple[int, int, int, int]:
        """è¤‡æ•°ã®æ¤œå‡ºçµæœã‚’çµ±åˆ"""
        
        # å“è³ªã‚¹ã‚³ã‚¢ã«ã‚ˆã‚‹é‡ã¿ä»˜ã‘
        weights = [result['quality_score'] / 100 for result in results]
        
        if sum(weights) == 0:
            # å…¨ã¦ä½å“è³ªã®å ´åˆã¯æœ€è‰¯ã‚’é¸æŠ
            best_result = max(results, key=lambda x: x['quality_score'])
            return best_result['bounds']
        
        # é‡ã¿ä»˜ãå¹³å‡ã«ã‚ˆã‚‹çµ±åˆ
        weighted_left = sum(result['bounds'][0] * weight for result, weight in zip(results, weights)) / sum(weights)
        weighted_top = sum(result['bounds'][1] * weight for result, weight in zip(results, weights)) / sum(weights)
        weighted_right = sum(result['bounds'][2] * weight for result, weight in zip(results, weights)) / sum(weights)
        weighted_bottom = sum(result['bounds'][3] * weight for result, weight in zip(results, weights)) / sum(weights)
        
        # å¤–ã‚Œå€¤é™¤å»
        bounds_list = [result['bounds'] for result in results]
        
        # å››åˆ†ä½ç¯„å›²ã«ã‚ˆã‚‹å¤–ã‚Œå€¤æ¤œå‡º
        lefts = [b[0] for b in bounds_list]
        tops = [b[1] for b in bounds_list]
        rights = [b[2] for b in bounds_list]
        bottoms = [b[3] for b in bounds_list]
        
        def remove_outliers(values):
            q1, q3 = np.percentile(values, [25, 75])
            iqr = q3 - q1
            lower_bound = q1 - 1.5 * iqr
            upper_bound = q3 + 1.5 * iqr
            return [v for v in values if lower_bound <= v <= upper_bound]
        
        filtered_lefts = remove_outliers(lefts)
        filtered_tops = remove_outliers(tops)
        filtered_rights = remove_outliers(rights)
        filtered_bottoms = remove_outliers(bottoms)
        
        # ãƒ•ã‚£ãƒ«ã‚¿æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã®ä¸­å¤®å€¤
        final_left = int(np.median(filtered_lefts) if filtered_lefts else weighted_left)
        final_top = int(np.median(filtered_tops) if filtered_tops else weighted_top)
        final_right = int(np.median(filtered_rights) if filtered_rights else weighted_right)
        final_bottom = int(np.median(filtered_bottoms) if filtered_bottoms else weighted_bottom)
        
        # æœ€çµ‚èª¿æ•´
        img = Image.open(image_path)
        width, height = img.size
        
        final_left = max(0, final_left)
        final_right = min(width - 1, final_right)
        final_top = max(0, final_top)
        final_bottom = min(height - 1, final_bottom)
        
        return (final_left, final_top, final_right, final_bottom)
    
    def _fallback_detection(self, image_path: str) -> Tuple[int, int, int, int]:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ¤œå‡ºï¼ˆæœ€ä½é™ã®çµæœï¼‰"""
        img = Image.open(image_path)
        width, height = img.size
        
        # å®‰å…¨ãªãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
        left = int(width * 0.05)
        right = int(width * 0.95)
        top = int(height * 0.30)
        bottom = int(height * 0.65)
        
        self.log(f"ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ¤œå‡º: {left}, {top}, {right}, {bottom}", "WARNING")
        
        return (left, top, right, bottom)
    
    # =====================================
    # 4. å¯è¦–åŒ–ãƒ»æ¤œè¨¼æ©Ÿèƒ½
    # =====================================
    
    def visualize_detection_process(self, image_path: str, save_path: str = None):
        """æ¤œå‡ºãƒ—ãƒ­ã‚»ã‚¹ã®å¯è¦–åŒ–"""
        if not PLOT_AVAILABLE:
            self.log("matplotlib ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“", "WARNING")
            return
        
        self.log("æ¤œå‡ºãƒ—ãƒ­ã‚»ã‚¹ã‚’å¯è¦–åŒ–ä¸­...", "INFO")
        
        # è¤‡æ•°ã®æ¤œå‡ºçµæœã‚’å–å¾—
        methods = [
            ("è‰²åˆ†æ", self.detect_by_color_analysis),
            ("ã‚¨ãƒƒã‚¸åˆ†æ", self.detect_by_edge_analysis),
            ("ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆåˆ†æ", self.detect_by_layout_analysis),
            ("ã‚ªãƒ¬ãƒ³ã‚¸ãƒãƒ¼æ¤œå‡º", self.detect_by_orange_bar)
        ]
        
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        fig.suptitle(f'é«˜ç²¾åº¦æ¤œå‡ºãƒ—ãƒ­ã‚»ã‚¹: {os.path.basename(image_path)}', fontsize=16, fontweight='bold')
        
        img = Image.open(image_path)
        
        # å…ƒç”»åƒ
        axes[0, 0].imshow(img)
        axes[0, 0].set_title('å…ƒç”»åƒ')
        axes[0, 0].axis('off')
        
        # å„æ‰‹æ³•ã®çµæœ
        colors = ['red', 'green', 'blue', 'orange', 'purple']
        
        for i, (method_name, method_func) in enumerate(methods[:4]):
            row = i // 2
            col = (i % 2) + 1
            
            axes[row, col].imshow(img)
            
            try:
                bounds = method_func(image_path)
                if bounds:
                    left, top, right, bottom = bounds
                    rect = patches.Rectangle((left, top), right-left, bottom-top,
                                           linewidth=3, edgecolor=colors[i], facecolor='none')
                    axes[row, col].add_patch(rect)
                    
                    quality = self._evaluate_bounds_quality(bounds, image_path)
                    axes[row, col].set_title(f'{method_name}\nå“è³ª: {quality:.1f}')
                else:
                    axes[row, col].set_title(f'{method_name}\næ¤œå‡ºå¤±æ•—')
            except Exception as e:
                axes[row, col].set_title(f'{method_name}\nã‚¨ãƒ©ãƒ¼')
            
            axes[row, col].axis('off')
        
        # çµ±åˆçµæœ
        axes[1, 2].imshow(img)
        final_bounds = self.ensemble_detection(image_path)
        left, top, right, bottom = final_bounds
        
        rect = patches.Rectangle((left, top), right-left, bottom-top,
                               linewidth=4, edgecolor='yellow', facecolor='none')
        axes[1, 2].add_patch(rect)
        
        final_quality = self._evaluate_bounds_quality(final_bounds, image_path)
        axes[1, 2].set_title(f'çµ±åˆçµæœ\nå“è³ª: {final_quality:.1f}')
        axes[1, 2].axis('off')
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            self.log(f"å¯è¦–åŒ–çµæœã‚’ä¿å­˜: {save_path}", "SUCCESS")
        
        plt.show()
    
    def verify_detection_accuracy(self, test_folder: str, ground_truth_file: str = None):
        """æ¤œå‡ºç²¾åº¦ã®æ¤œè¨¼"""
        self.log("æ¤œå‡ºç²¾åº¦ã‚’æ¤œè¨¼ä¸­...", "INFO")
        
        if not os.path.exists(test_folder):
            self.log(f"ãƒ†ã‚¹ãƒˆãƒ•ã‚©ãƒ«ãƒ€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {test_folder}", "ERROR")
            return
        
        # ãƒ†ã‚¹ãƒˆç”»åƒã®å‡¦ç†
        test_images = [f for f in os.listdir(test_folder) 
                      if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
        
        if not test_images:
            self.log("ãƒ†ã‚¹ãƒˆç”»åƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“", "ERROR")
            return
        
        results = []
        
        for image_file in test_images:
            image_path = os.path.join(test_folder, image_file)
            
            try:
                bounds = self.ensemble_detection(image_path)
                quality = self._evaluate_bounds_quality(bounds, image_path)
                
                results.append({
                    'image': image_file,
                    'bounds': bounds,
                    'quality': quality
                })
                
                self.log(f"âœ… {image_file}: å“è³ª {quality:.1f}", "SUCCESS")
                
            except Exception as e:
                self.log(f"âŒ {image_file}: ã‚¨ãƒ©ãƒ¼ - {e}", "ERROR")
        
        # çµ±è¨ˆæƒ…å ±
        if results:
            qualities = [r['quality'] for r in results]
            avg_quality = np.mean(qualities)
            std_quality = np.std(qualities)
            
            self.log(f"\nğŸ“Š æ¤œè¨¼çµæœ:", "INFO")
            self.log(f"   å‡¦ç†æˆåŠŸ: {len(results)}/{len(test_images)}", "INFO")
            self.log(f"   å¹³å‡å“è³ª: {avg_quality:.1f} Â± {std_quality:.1f}", "INFO")
            self.log(f"   æœ€é«˜å“è³ª: {max(qualities):.1f}", "INFO")
            self.log(f"   æœ€ä½å“è³ª: {min(qualities):.1f}", "INFO")
            
            # å“è³ªåˆ†å¸ƒ
            excellent = sum(1 for q in qualities if q >= 80)
            good = sum(1 for q in qualities if 60 <= q < 80)
            fair = sum(1 for q in qualities if 40 <= q < 60)
            poor = sum(1 for q in qualities if q < 40)
            
            self.log(f"   å“è³ªåˆ†å¸ƒ:", "INFO")
            self.log(f"     å„ªç§€ (80+): {excellent}", "INFO")
            self.log(f"     è‰¯å¥½ (60-79): {good}", "INFO")
            self.log(f"     æ™®é€š (40-59): {fair}", "INFO")
            self.log(f"     æ”¹å–„è¦ (<40): {poor}", "INFO")
        
        return results
    
    # =====================================
    # 5. ãƒ¡ã‚¤ãƒ³å‡¦ç†ãƒ»ãƒãƒƒãƒå‡¦ç†
    # =====================================
    
    def crop_image_with_high_precision(self, image_path: str, output_path: str = None) -> bool:
        """é«˜ç²¾åº¦ã§ç”»åƒã‚’åˆ‡ã‚ŠæŠœã"""
        try:
            self.log(f"ğŸ¯ é«˜ç²¾åº¦åˆ‡ã‚ŠæŠœãé–‹å§‹: {os.path.basename(image_path)}", "INFO")
            
            # çµ±åˆæ¤œå‡º
            bounds = self.ensemble_detection(image_path)
            
            # åˆ‡ã‚ŠæŠœãå®Ÿè¡Œ
            img = Image.open(image_path)
            left, top, right, bottom = bounds
            cropped_img = img.crop(bounds)
            
            # å‡ºåŠ›ãƒ‘ã‚¹è¨­å®š
            if output_path is None:
                base_name = os.path.splitext(os.path.basename(image_path))[0]
                output_path = f"graphs/cropped_high_precision/{base_name}_cropped_hp.png"
            
            # å‡ºåŠ›ãƒ•ã‚©ãƒ«ãƒ€ä½œæˆ
            os.makedirs(os.path.dirname(output_path), exist_ok=True)
            
            # ä¿å­˜
            cropped_img.save(output_path)
            
            # å“è³ªè©•ä¾¡
            quality = self._evaluate_bounds_quality(bounds, image_path)
            
            self.log(f"âœ… åˆ‡ã‚ŠæŠœãå®Œäº†: {output_path}", "SUCCESS")
            self.log(f"   åˆ‡ã‚ŠæŠœãç¯„å›²: {bounds}", "INFO")
            self.log(f"   å“è³ªã‚¹ã‚³ã‚¢: {quality:.1f}", "INFO")
            
            return True
            
        except Exception as e:
            self.log(f"âŒ åˆ‡ã‚ŠæŠœãã‚¨ãƒ©ãƒ¼: {e}", "ERROR")
            return False
    
    def process_batch_high_precision(self, input_folder: str = "graphs", 
                                   output_folder: str = "graphs/cropped_high_precision"):
        """é«˜ç²¾åº¦ãƒãƒƒãƒå‡¦ç†"""
        self.log(f"ğŸš€ é«˜ç²¾åº¦ãƒãƒƒãƒå‡¦ç†é–‹å§‹", "INFO")
        
        if not os.path.exists(input_folder):
            self.log(f"å…¥åŠ›ãƒ•ã‚©ãƒ«ãƒ€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {input_folder}", "ERROR")
            return
        
        # å¯¾è±¡ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«
        image_files = [f for f in os.listdir(input_folder)
                      if f.lower().endswith(('.png', '.jpg', '.jpeg'))
                      and not f.endswith('_cropped.png')
                      and not f.endswith('_cropped_hp.png')]
        
        if not image_files:
            self.log("å‡¦ç†å¯¾è±¡ã®ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“", "ERROR")
            return
        
        os.makedirs(output_folder, exist_ok=True)
        
        self.log(f"ğŸ“ å‡¦ç†å¯¾è±¡: {len(image_files)}å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«", "INFO")
        
        successful = 0
        failed = []
        qualities = []
        
        for i, filename in enumerate(image_files, 1):
            self.log(f"\n[{i}/{len(image_files)}] å‡¦ç†ä¸­: {filename}", "INFO")
            
            input_path = os.path.join(input_folder, filename)
            base_name = os.path.splitext(filename)[0]
            output_path = os.path.join(output_folder, f"{base_name}_cropped_hp.png")
            
            if self.crop_image_with_high_precision(input_path, output_path):
                successful += 1
                
                # å“è³ªè©•ä¾¡
                bounds = self.ensemble_detection(input_path)
                quality = self._evaluate_bounds_quality(bounds, input_path)
                qualities.append(quality)
            else:
                failed.append(filename)
        
        # ãƒãƒƒãƒå‡¦ç†çµæœ
        self.log(f"\nğŸ‰ ãƒãƒƒãƒå‡¦ç†å®Œäº†!", "SUCCESS")
        self.log(f"âœ… æˆåŠŸ: {successful}/{len(image_files)}", "SUCCESS")
        
        if failed:
            self.log(f"âŒ å¤±æ•—: {len(failed)}å€‹", "ERROR")
            for f in failed:
                self.log(f"  - {f}", "ERROR")
        
        if qualities:
            avg_quality = np.mean(qualities)
            self.log(f"ğŸ“Š å¹³å‡å“è³ª: {avg_quality:.1f}", "INFO")
        
        self.log(f"ğŸ“ å‡ºåŠ›ãƒ•ã‚©ãƒ«ãƒ€: {output_folder}", "INFO")
        
        # å‡¦ç†ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
        report = {
            'timestamp': datetime.now().isoformat(),
            'input_folder': input_folder,
            'output_folder': output_folder,
            'total_files': len(image_files),
            'successful': successful,
            'failed': failed,
            'average_quality': avg_quality if qualities else 0,
            'quality_scores': qualities
        }
        
        report_path = f"high_precision_batch_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        self.log(f"ğŸ“‹ ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜: {report_path}", "INFO")


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("=" * 60)
    print("ğŸ¯ é«˜ç²¾åº¦ãƒ‘ãƒãƒ³ã‚³ã‚°ãƒ©ãƒ•åˆ‡ã‚ŠæŠœããƒ„ãƒ¼ãƒ«")
    print("=" * 60)
    print("ğŸ”¬ è¤‡æ•°ã®AIæ¤œå‡ºæ‰‹æ³•ã‚’çµ±åˆã—ãŸæœ€é«˜ç²¾åº¦ç‰ˆ")
    print("ğŸ“Š è©³ç´°ãªå“è³ªè©•ä¾¡ãƒ»å¯è¦–åŒ–æ©Ÿèƒ½ä»˜ã")
    
    cropper = HighPrecisionCropper()
    
    # å…¥åŠ›ãƒ•ã‚©ãƒ«ãƒ€ãƒã‚§ãƒƒã‚¯
    input_folder = "graphs"
    if not os.path.exists(input_folder):
        print(f"\nâŒ å…¥åŠ›ãƒ•ã‚©ãƒ«ãƒ€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {input_folder}")
        print("ğŸ“ 'graphs' ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆã—ã¦ç”»åƒã‚’é…ç½®ã—ã¦ãã ã•ã„")
        return
    
    # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢
    image_files = [f for f in os.listdir(input_folder)
                  if f.lower().endswith(('.png', '.jpg', '.jpeg'))
                  and not f.endswith('_cropped.png')
                  and not f.endswith('_cropped_hp.png')]
    
    if not image_files:
        print(f"\nâŒ å‡¦ç†å¯¾è±¡ã®ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return
    
    print(f"\nğŸ“ è¦‹ã¤ã‹ã£ãŸç”»åƒãƒ•ã‚¡ã‚¤ãƒ« ({len(image_files)}å€‹):")
    for i, file in enumerate(image_files[:10], 1):  # æœ€åˆã®10å€‹ã®ã¿è¡¨ç¤º
        print(f"   {i}. {file}")
    if len(image_files) > 10:
        print(f"   ... ä»– {len(image_files) - 10}å€‹")
    
    # å‡¦ç†ãƒ¢ãƒ¼ãƒ‰é¸æŠ
    print(f"\nğŸ¯ å‡¦ç†ãƒ¢ãƒ¼ãƒ‰ã‚’é¸æŠ:")
    print("1. ğŸš€ å…¨è‡ªå‹•é«˜ç²¾åº¦ãƒãƒƒãƒå‡¦ç†ï¼ˆæ¨å¥¨ï¼‰")
    print("2. ğŸ“· å˜ä¸€ç”»åƒã®é«˜ç²¾åº¦å‡¦ç† + å¯è¦–åŒ–")
    print("3. ğŸ”¬ æ¤œå‡ºç²¾åº¦ã®æ¤œè¨¼ãƒ†ã‚¹ãƒˆ")
    print("4. ğŸ“Š æ¤œå‡ºãƒ—ãƒ­ã‚»ã‚¹ã®è©³ç´°å¯è¦–åŒ–")
    
    try:
        choice = input("\né¸æŠ (1-4): ").strip()
        
        if choice == "1":
            # å…¨è‡ªå‹•ãƒãƒƒãƒå‡¦ç†
            cropper.process_batch_high_precision()
            
        elif choice == "2":
            # å˜ä¸€ç”»åƒå‡¦ç†
            print(f"\nğŸ“ ç”»åƒã‚’é¸æŠ:")
            for i, file in enumerate(image_files, 1):
                print(f"{i}. {file}")
            
            try:
                file_num = int(input("ç”»åƒç•ªå·ã‚’é¸æŠ: "))
                if 1 <= file_num <= len(image_files):
                    selected_file = image_files[file_num - 1]
                    image_path = os.path.join(input_folder, selected_file)
                    
                    # é«˜ç²¾åº¦å‡¦ç†
                    success = cropper.crop_image_with_high_precision(image_path)
                    
                    # å¯è¦–åŒ–
                    if success and PLOT_AVAILABLE:
                        show_viz = input("\nğŸ” æ¤œå‡ºãƒ—ãƒ­ã‚»ã‚¹ã‚’å¯è¦–åŒ–ã—ã¾ã™ã‹ï¼Ÿ (y/n): ").strip().lower()
                        if show_viz != 'n':
                            cropper.visualize_detection_process(image_path)
                else:
                    print("âŒ ç„¡åŠ¹ãªç•ªå·ã§ã™")
            except ValueError:
                print("âŒ æ•°å­—ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
                
        elif choice == "3":
            # ç²¾åº¦æ¤œè¨¼
            test_folder = input("ãƒ†ã‚¹ãƒˆç”»åƒãƒ•ã‚©ãƒ«ãƒ€ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: graphs): ").strip()
            if not test_folder:
                test_folder = "graphs"
            
            cropper.verify_detection_accuracy(test_folder)
            
        elif choice == "4":
            # è©³ç´°å¯è¦–åŒ–
            if not PLOT_AVAILABLE:
                print("âŒ matplotlib ãŒå¿…è¦ã§ã™")
                return
            
            print(f"\nğŸ“ ç”»åƒã‚’é¸æŠ:")
            for i, file in enumerate(image_files, 1):
                print(f"{i}. {file}")
            
            try:
                file_num = int(input("ç”»åƒç•ªå·ã‚’é¸æŠ: ").strip())
                if 1 <= file_num <= len(image_files):
                    selected_file = image_files[file_num - 1]
                    image_path = os.path.join(input_folder, selected_file)
                    
                    save_viz = input("å¯è¦–åŒ–çµæœã‚’ä¿å­˜ã—ã¾ã™ã‹ï¼Ÿ (y/n): ").strip().lower()
                    save_path = None
                    if save_viz == 'y':
                        base_name = os.path.splitext(selected_file)[0]
                        save_path = f"detection_process_{base_name}.png"
                    
                    cropper.visualize_detection_process(image_path, save_path)
                else:
                    print("âŒ ç„¡åŠ¹ãªç•ªå·ã§ã™")
            except ValueError:
                print("âŒ æ•°å­—ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
        else:
            print("âŒ ç„¡åŠ¹ãªé¸æŠã§ã™")
            
    except KeyboardInterrupt:
        print("\n\nâš ï¸ å‡¦ç†ãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
    except Exception as e:
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    
    print(f"\nâœ¨ å‡¦ç†å®Œäº†")


if __name__ == "__main__":
    main()